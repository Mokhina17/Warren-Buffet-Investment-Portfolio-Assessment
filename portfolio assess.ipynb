{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "185502ee-9891-4cca-a221-0f1ffe425905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Add a StreamHandler\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.covariance import LedoitWolf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "9b2e3b0b-5a73-4df9-b31a-078aa6f463b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__name__ value: __main__\n"
     ]
    }
   ],
   "source": [
    "print(f\"__name__ value: {__name__}\")\n",
    "logger = logging.getLogger(\"my_main_script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "c0ffd25e-1eac-440a-9ca1-0a0187aa0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 模型参数\n",
    "rf_params = {\n",
    "    'n_estimators': 1000,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 'sqrt',\n",
    "    'random_state': 42,\n",
    "    'warm_start' : True\n",
    "}\n",
    "\n",
    "# 训练模型\n",
    "rf_model = RandomForestRegressor(**rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "44042cc1-4903-4594-bbf1-93ba5a99297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 39) (157,) (26, 39) (26,)\n",
      "Training period: 2014-07-31 00:00:00 to 2015-01-31 00:00:00\n",
      "Testing period: 2015-01-31 00:00:00 to 2015-02-28 00:00:00\n",
      "(157, 39) (157,) (26, 39) (26,)\n"
     ]
    }
   ],
   "source": [
    "rf_data = pd.read_csv('model_data.csv')\n",
    "rf_data['date'] = pd.to_datetime(rf_data['date'])\n",
    "rf_data.set_index(['date'], inplace=True)\n",
    "\n",
    "# 确定训练集的开始和结束日期\n",
    "train_start = rf_data.index.min()\n",
    "train_end = train_start + pd.DateOffset(months=6)\n",
    "test_start = train_end\n",
    "test_end = test_start + pd.DateOffset(months=1)\n",
    "\n",
    "# 分割数据集为训练集（前6个月）和预测集（第7个月）\n",
    "rf_data_for_training = rf_data[(rf_data.index >= train_start) & (rf_data.index < train_end)]\n",
    "rf_data_using_model_predicting = rf_data[(rf_data.index >= test_start) & (rf_data.index < test_end)]\n",
    "\n",
    "# 定义特征和目标变量\n",
    "features = rf_data.columns[~rf_data.columns.isin(['TICKER', 'RET'])].tolist()\n",
    "X_train = rf_data_for_training[features]\n",
    "y_train = rf_data_for_training['RET']\n",
    "X_test = rf_data_using_model_predicting[features]\n",
    "y_test = rf_data_using_model_predicting['RET']\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "print(\"Training period:\", train_start, \"to\", train_end)\n",
    "print(\"Testing period:\", test_start, \"to\", test_end)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "91632d70-8631-4fe0-a087-f3d479d10335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.001071484773941469\n",
      "Mean Absolute Error: 1.3535129710986291\n",
      "R-squared Score: -0.0669844862474871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "# 训练模型\n",
    "\n",
    "# 模型参数\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    # 'max_depth': 21,\n",
    "    # 'min_samples_split': 2,\n",
    "    # 'min_samples_leaf': 4,\n",
    "    # 'max_features': 'auto',\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# 2. 模型创建和训练\n",
    "rf_model = RandomForestRegressor(**rf_params)\n",
    "pipeline = Pipeline([('rf', rf_model)])\n",
    "\n",
    "pipeline.fit(X_train.values, y_train)\n",
    "\n",
    "# 3. 模型评估\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mape}\")\n",
    "\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "56820542-c70e-49c1-8b28-4b85791a33ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction R²: -0.0670\n",
      "Prediction MSE: 0.0011\n",
      "Prediction MAPE: 1.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_predict = rf_data_using_model_predicting[features]\n",
    "y_actual = rf_data_using_model_predicting['RET']\n",
    "\n",
    "# 在最后一个月的预测集上进行预测\n",
    "y_predict = pipeline.predict(X_predict)\n",
    "\n",
    "r2_predict = r2_score(y_actual, y_predict)\n",
    "mse_predict = mean_squared_error(y_actual, y_predict)\n",
    "mape_predict = mean_absolute_percentage_error(y_actual, y_predict)\n",
    "\n",
    "print(f'Prediction R²: {r2_predict:.4f}')\n",
    "print(f'Prediction MSE: {mse_predict:.4f}')\n",
    "print(f'Prediction MAPE: {mape_predict:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5528f018-0c12-4de2-9a96-460faf29fe44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "4f771316-6da6-48a2-a62d-cd02a1c16924",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_keep = ['Size', 'bm', 'Momentum', 'r2_1', 'r12_2', 'r12_7', 'ShortTermReversal',\n",
    "       'market_cap', 'DollarVolume', 'spread', 'RET', 'idio_vol', 'Beta',\n",
    "       'BetaSquared', 'pe_op_basic', 'pe_op_dil', 'Volatility', 'SUV',\n",
    "       '52_week_high', 'Rel_to_high', 'TB3MS', 'T10Y2Y', 'BAA10Y', 'roa',\n",
    "       'roe', 'roce', 'debt_assets', 'debt_capital', 'de_ratio', 'cash_ratio',\n",
    "       'quick_ratio', 'curr_ratio', 'at_turn', 'inv_turn', 'accrual', 'vwretd',\n",
    "       'ewretd', 'sprtrn', 'LME', 'LTurnover', 'TICKER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "2dca2aca-e699-44fc-9de7-4c9086e96a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_data = pd.read_csv('model_data.csv')\n",
    "opt_data['date'] = pd.to_datetime(opt_data['date'])\n",
    "opt_data.set_index(['date', 'TICKER'], inplace=True)\n",
    "opt_data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "c88c279b-2aad-4aa1-b5f9-40d3bbed41e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_features = opt_data.columns[~opt_data.columns.isin(['RET','TICKER'])].tolist()\n",
    "target = ['RET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "dac6a726-b31f-4efd-8354-466019f0e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_data = pd.read_csv('final_data_after_missing_value_handle_with_better_features.csv')\n",
    "featured_data['date'] = pd.to_datetime(featured_data['date'])\n",
    "featured_data.set_index(['date', 'TICKER'], inplace=True)\n",
    "featured_data.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "id": "1fcec273-0c02-4cd9-bcde-85bbe7b635c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_portfolio_composition(weights, stocks):\n",
    "    \"\"\"\n",
    "    Display the composition of the portfolio with ticker names and weights.\n",
    "    \n",
    "    Parameters:\n",
    "    weights (numpy.array): Optimized weights for the portfolio\n",
    "    stocks (pandas.Index or list): The stock tickers in the portfolio\n",
    "    threshold (float): Minimum weight to include in the display (default: 1%)\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A dataframe showing the portfolio composition\n",
    "    str: A string representation of the portfolio composition\n",
    "    \"\"\"\n",
    "    # Create a dataframe with tickers and weights\n",
    "    portfolio = pd.DataFrame({\n",
    "        'Ticker': stocks,\n",
    "        'Weight': weights\n",
    "    })\n",
    "    threshold=0.01\n",
    "    # Sort by weight in descending order\n",
    "    portfolio = portfolio.sort_values('Weight', ascending=False)\n",
    "    \n",
    "    # Filter out weights below the threshold\n",
    "    portfolio = portfolio[portfolio['Weight'] >= threshold]\n",
    "    \n",
    "    # Calculate the sum of displayed weights\n",
    "    displayed_weight_sum = portfolio['Weight'].sum()\n",
    "    \n",
    "    # Add a row for \"Others\" if necessary\n",
    "    if displayed_weight_sum < 1:\n",
    "        others_weight = 1 - displayed_weight_sum\n",
    "        others_row = pd.DataFrame({\n",
    "            'Ticker': ['Others'],\n",
    "            'Weight': [others_weight]\n",
    "        })\n",
    "        portfolio = pd.concat([portfolio, others_row])\n",
    "    \n",
    "    # Format weights as percentages\n",
    "    portfolio['Weight'] = portfolio['Weight'].apply(lambda x: f\"{x:.2%}\")\n",
    "    \n",
    "    # Reset index for clean display\n",
    "    portfolio = portfolio.reset_index(drop=True)\n",
    "    \n",
    "    # Create a string representation\n",
    "    portfolio_str = portfolio.to_string(index=False)\n",
    "    \n",
    "    return portfolio, portfolio_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "c0d9c5a9-bba0-4dfb-9fa5-b477d43ca473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "def get_data_for_date_range(df, start_date, end_date):\n",
    "    # return df.loc[start_date:end_date]\n",
    "    if start_date is None:\n",
    "        data = df.loc[:end_date]\n",
    "    else:\n",
    "        data = df.loc[start_date:end_date]\n",
    "    if data.empty:\n",
    "        logger.warning(f\"No data found between {start_date} and {end_date}\")\n",
    "    return data\n",
    "\n",
    "def prepare_training_data(df, features, target):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    return X, y\n",
    "\n",
    "def fit_and_predict(model, X_train, y_train, X_test):\n",
    "    # logger.info(f\"fit_and_predict: X_train shape: {X_train.shape}, type: {type(X_train)}\")\n",
    "    # logger.info(f\"fit_and_predict: y_train shape: {y_train.shape}, type: {type(y_train)}\")\n",
    "    # logger.info(f\"fit_and_predict: X_test shape: {X_test.shape}, type: {type(X_test)}\")\n",
    "    \n",
    "    # Train the new model\n",
    "    # logger.info(\"start fitting\")\n",
    "    model.fit(X_train.values, y_train)\n",
    "    # logger.info(\"end fitting\")\n",
    "\n",
    "    predictions = model.predict(X_test.values)    \n",
    "    # logger.info(\"end predict\")\n",
    "    # 计算预测方差\n",
    "    variance = calculate_predicted_variance(model, X_test)\n",
    "    \n",
    "    return predictions, variance\n",
    "\n",
    "def get_final_estimator(model):\n",
    "    if hasattr(model, 'steps'):  # 检查是否是 Pipeline\n",
    "        return model.steps[-1][1]  # 返回 Pipeline 的最后一个估计器\n",
    "    return model\n",
    "\n",
    "def calculate_predicted_variance(model, X_test):\n",
    "    final_estimator = get_final_estimator(model)\n",
    "    \n",
    "    if hasattr(final_estimator, 'predict_proba'):\n",
    "        proba = final_estimator.predict_proba(X_test)\n",
    "        return np.var(proba, axis=1)\n",
    "    elif hasattr(final_estimator, 'estimators_'):\n",
    "        predictions = np.array([tree.predict(X_test.values) for tree in final_estimator.estimators_])\n",
    "        return np.var(predictions, axis=0)\n",
    "    else:\n",
    "        logger.warning(\"模型不提供方差估计，返回固定值\")\n",
    "        return np.full(X_test.shape[0], 1e-6)\n",
    "\n",
    "\n",
    "# 分配相等的权重\n",
    "def equal_weight_portfolio(expected_returns):\n",
    "    n = len(expected_returns)\n",
    "    equal_weights = np.ones(n) / n\n",
    "    return equal_weights\n",
    "\n",
    "# 优化投资组合权重\n",
    "def optimize_portfolio(expected_returns, cov_matrix, lambda_risk_aversion, max_iter=1000):\n",
    "    n = len(expected_returns)\n",
    "    \n",
    "    expected_returns = np.array(expected_returns).flatten()\n",
    "\n",
    "\n",
    "    def objective(weights):\n",
    "        portfolio_return = np.sum(expected_returns * weights)\n",
    "        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return -(portfolio_return - lambda_risk_aversion * portfolio_volatility)\n",
    "\n",
    "    constraints = (\n",
    "        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},  # 权重之和为1\n",
    "        # {'type': 'ineq', 'fun': lambda x: 0.5 - np.max(x)}  # 单个资产最大权重为50%\n",
    "    )\n",
    "    bounds = tuple((0, 1) for _ in range(n))  # 权重在0到1之间\n",
    "\n",
    "    result = minimize(objective, n * [1./n], method='SLSQP', bounds=bounds, \n",
    "                      constraints=constraints, options={'maxiter': max_iter})\n",
    "    \n",
    "    if not result.success:\n",
    "        logger.warning(f\"Optimization failed: {result.message}\")\n",
    "        return np.ones(n) / n  # 返回等权重作为后备方案\n",
    "    \n",
    "    return result.x\n",
    "\n",
    "def predict_returns(df, start_date, next_month, features, target, model):\n",
    "    try:\n",
    "        logger.info(f\"Predicting returns from {start_date} to {next_month}\")\n",
    "        \n",
    "        # Filter data for the training period (up to and including start_date)\n",
    "        train = df[df.index.get_level_values('date') <= start_date]\n",
    "        \n",
    "        # Filter data for the test period (next_month only)\n",
    "        test = df[df.index.get_level_values('date') == next_month]\n",
    "\n",
    "        logger.info(f\"Train data shape: {train.shape}\")\n",
    "        logger.info(f\"Test data shape: {test.shape}\")\n",
    "        \n",
    "        X_train, y_train = prepare_training_data(train, features, target)\n",
    "        X_test = test[features]    \n",
    "        logger.info(f\"X_train shape: {X_train.shape}\")\n",
    "        logger.info(f\"y_train shape: {y_train.shape}\")\n",
    "        logger.info(f\"X_test shape: {X_test.shape}\")\n",
    "        \n",
    "        if X_train.empty or y_train.empty:\n",
    "            raise ValueError(\"Training data is empty\")\n",
    "        \n",
    "        if X_test.empty:\n",
    "            raise ValueError(f\"No data available for the next month: {next_month}\")\n",
    "        \n",
    "        predictions, predicted_variance = fit_and_predict(model, X_train, y_train, X_test)\n",
    "        logger.info(f\"Predictions shape: {predictions.shape}\")\n",
    "        logger.info(f\"Predicted variance shape: {predicted_variance.shape}\")\n",
    "                \n",
    "        # Get actual returns for the test period (next_month)\n",
    "        actual_returns = test[target]\n",
    "\n",
    "        # 添加这些日志语句\n",
    "        logger.info(f\"actual_returns shape: {actual_returns.shape}, type: {type(actual_returns)}\")\n",
    "        logger.info(f\"predictions shape: {predictions.shape}, type: {type(predictions)}\")\n",
    "        \n",
    "        # 确保 predictions 和 actual_returns 都是 DataFrame\n",
    "        predictions_df = pd.DataFrame(predictions, index=actual_returns.index, columns=actual_returns.columns)\n",
    "        # metrics = calculate_model_metrics(actual_returns, predictions_df)\n",
    "        # logger.info(f\"Model Evaluation Metrics: {metrics}\")\n",
    "\n",
    "        return predictions_df, pd.Series(predicted_variance, index=actual_returns.index), actual_returns\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in predict_returns: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def calculate_model_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算模型评估指标：MSE, RMSE, MAE, R2\n",
    "    \n",
    "    参数:\n",
    "    y_true (pd.DataFrame): 实际值\n",
    "    y_pred (pd.DataFrame): 预测值\n",
    "    \n",
    "    返回:\n",
    "    dict: 包含 mse, rmse, mae, r2 的字典\n",
    "    \"\"\"\n",
    "    # 确保输入是DataFrame并且只有一列\n",
    "    # assert isinstance(y_true, pd.DataFrame) and isinstance(y_pred, pd.DataFrame), \"Inputs must be DataFrames\"\n",
    "    # assert y_true.shape[1] == 1 and y_pred.shape[1] == 1, \"Inputs must have only one column\"\n",
    "    \n",
    "    # 计算指标\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return mse, rmse, mae, r2\n",
    "\n",
    "def get_risk_free_rate(featured_data, date):\n",
    "    rf_data = featured_data.loc[featured_data.index.get_level_values('date') == date, 'TB3MS']\n",
    "    if len(rf_data) > 0:\n",
    "        annual_rf_rate = rf_data.iloc[0] / 100\n",
    "        logger.info(f\"Annual Risk-free rate: {annual_rf_rate}\")\n",
    "        monthly_rf_rate = (1 + annual_rf_rate) ** (1/12) - 1\n",
    "        logger.info(f\"Monthly Risk-free rate: {monthly_rf_rate}\")\n",
    "    else:\n",
    "        logger.warning(f\"No risk-free rate data for {date}. Using average of last 3 months as default.\")\n",
    "        # 使用最近3个月的平均值作为默认值\n",
    "        last_3_months = featured_data.loc[featured_data.index.get_level_values('date') < date, 'TB3MS'].tail(3)\n",
    "        if len(last_3_months) > 0:\n",
    "            annual_rf_rate = last_3_months.mean() / 100\n",
    "            monthly_rf_rate = (1 + annual_rf_rate) ** (1/12) - 1\n",
    "        else:\n",
    "            logger.warning(\"No historical risk-free rate data available. Using 0 as default.\")\n",
    "            monthly_rf_rate = 0\n",
    "    return monthly_rf_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "3d8f8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_optimal_covariance(historical_data, current_tickers, target_column, min_history_length=252, min_data_pct=0):\n",
    "    \"\"\"\n",
    "    估计最优协方差矩阵，处理不同时间点股票不同的问题，并减少填充的影响。\n",
    "    \n",
    "    参数:\n",
    "    historical_data (pd.DataFrame): 包含历史数据的DataFrame，索引为MultiIndex（日期和股票代码）\n",
    "    current_tickers (list): 当前时间点的股票代码列表\n",
    "    target_column (str): 目标列名（例如，'returns'）\n",
    "    min_history_length (int): 用于估计的最小历史数据长度\n",
    "    min_data_pct (float): 股票需要的最小数据百分比\n",
    "    \n",
    "    返回:\n",
    "    np.array: 估计的协方差矩阵\n",
    "    \"\"\"    \n",
    "    historical_data = historical_data.sort_index()\n",
    "    dates = historical_data.index.get_level_values('date').unique()\n",
    "    recent_dates = dates[-min_history_length:] if len(dates) > min_history_length else dates\n",
    "    \n",
    "    recent_data = historical_data.loc[historical_data.index.get_level_values('date').isin(recent_dates)]\n",
    "    recent_data = recent_data[recent_data.index.get_level_values('TICKER').isin(current_tickers)]\n",
    "    \n",
    "    if recent_data.empty:\n",
    "        raise ValueError(\"No recent data available for the specified tickers\")\n",
    "    \n",
    "    pivot_data = recent_data[target_column].unstack(level='TICKER')\n",
    "    \n",
    "    # 计算每个股票的数据完整性\n",
    "    data_completeness = pivot_data.notna().sum() / len(pivot_data)\n",
    "    valid_tickers = data_completeness[data_completeness >= min_data_pct].index.tolist()\n",
    "\n",
    "    logger.info(f\"estimate: valid tickers: {valid_tickers}\")\n",
    "    \n",
    "    if not valid_tickers:\n",
    "        raise ValueError(\"No stocks with sufficient data\")\n",
    "    \n",
    "    valid_data = pivot_data[valid_tickers]\n",
    "\n",
    "    # logger.info(f\"estimate: valid_data: {valid_data.head()}\")\n",
    "\n",
    "    \n",
    "    # 使用线性插值填充缺失值\n",
    "    filled_data = valid_data.interpolate(method='linear', axis=0).fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "    # 计算每个股票的平均收益率和波动率\n",
    "    mean_returns = filled_data.mean()\n",
    "    std_returns = filled_data.std()\n",
    "    \n",
    "    # 对于缺失值较多的股票，使用其历史平均收益率和波动率来模拟数据\n",
    "    for ticker in valid_tickers:\n",
    "        missing_dates = filled_data[ticker].isna()\n",
    "        if missing_dates.sum() > 0:\n",
    "            simulated_returns = np.random.normal(mean_returns[ticker], std_returns[ticker], size=missing_dates.sum())\n",
    "            filled_data.loc[missing_dates, ticker] = simulated_returns\n",
    "    \n",
    "    # 计算加权系数\n",
    "    weights = data_completeness[valid_tickers].values\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    # 加权数据\n",
    "    weighted_data = filled_data * weights\n",
    "    \n",
    "    # 使用Ledoit-Wolf方法估计协方差矩阵\n",
    "    lw = LedoitWolf()\n",
    "    # logger.info(\"start lw fitting\")\n",
    "    cov_matrix = lw.fit(weighted_data.values).covariance_\n",
    "    # logger.info(\"end lw fitting\")\n",
    "    \n",
    "    if isinstance(pivot_data.columns, pd.MultiIndex):\n",
    "        valid_tickers = [t[1] if isinstance(t, tuple) else t for t in valid_tickers]\n",
    "        \n",
    "    return cov_matrix, valid_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "e36c9098-f51a-4419-a27d-33c675ccfafb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def process_single_period(df, featured_data, start_date, next_month, opt_features, target, model, lambda_risk_aversion):\n",
    "#     try:\n",
    "#         # logger.info(f\"Processing period from {start_date} to {next_month}\")\n",
    "        \n",
    "#         # historical_data = df[df.index.get_level_values('date') <= start_date]\n",
    "#         # logger.info(f\"Historical data shape: {historical_data.shape}\")\n",
    "        \n",
    "#         # logger.info(\"About to call predict_returns function\")\n",
    "\n",
    "#         # predicted_returns, predicted_variance, actual_returns = predict_returns(df, start_date, next_month, opt_features, target, model)\n",
    "\n",
    "#         # logger.info(\"predict_returns function completed\")\n",
    "\n",
    "#         # 获取下一个月的股票列表\n",
    "#         next_month_stocks = df.loc[next_month].index.get_level_values('TICKER')\n",
    "#         logger.info(f\"Next month stocks: {next_month_stocks}\")\n",
    "#         logger.info(f\"Number of stocks for next month: {len(next_month_stocks)}\")\n",
    "\n",
    "#         # # 确保 predicted_returns 和 actual_returns 具有相同的长度和顺序\n",
    "#         # if len(predicted_returns) != len(next_month_stocks):\n",
    "#         #     raise ValueError(f\"Mismatch between predicted returns length ({len(predicted_returns)}) and number of stocks ({len(next_month_stocks)})\")\n",
    "        \n",
    "#         # # # 使用这些股票的历史收益率数据计算协方差矩阵\n",
    "#         # # historical_returns = historical_data.loc[(slice(None), next_month_stocks), target].unstack().pct_change().dropna()\n",
    "#         # # cov_matrix = historical_returns.cov()\n",
    "        \n",
    "#         # # logger.info(f\"Covariance matrix shape: {cov_matrix.shape}\")\n",
    "#         # # logger.info(f\"Predicted returns shape: {predicted_returns.shape}\")\n",
    "        \n",
    "#         # # if cov_matrix.shape[0] != len(predicted_returns):\n",
    "#         # #     raise ValueError(f\"Mismatch between covariance matrix shape {cov_matrix.shape} and predicted returns length {len(predicted_returns)}\")\n",
    "\n",
    "\n",
    "#         # # optimal_weights = optimize_portfolio(predicted_returns, cov_matrix, lambda_risk_aversion)\n",
    "        \n",
    "#         # # 在 process_single_period 函数中\n",
    "#         # current_tickers = df.loc[next_month].index.get_level_values('TICKER')\n",
    "#         # cov_matrix = estimate_optimal_covariance(historical_data, current_tickers, target)\n",
    "\n",
    "#         # # 确保 predicted_returns 和 cov_matrix 的顺序一致\n",
    "#         # predicted_returns_aligned = predicted_returns[np.isin(current_tickers, df.loc[next_month].index)]\n",
    "#         # cov_matrix_aligned = cov_matrix[np.isin(current_tickers, df.loc[next_month].index)][:, np.isin(current_tickers, df.loc[next_month].index)]\n",
    "\n",
    "#         logger.info(f\"Processing period from {start_date} to {next_month}\")\n",
    "        \n",
    "#         historical_data = df[df.index.get_level_values('date') <= start_date]\n",
    "#         logger.info(f\"Historical data shape: {historical_data.shape}\")\n",
    "        \n",
    "#         # logger.info(\"About to call predict_returns function\")\n",
    "\n",
    "#          # 估计协方差矩阵\n",
    "#         cov_matrix, valid_tickers = estimate_optimal_covariance(historical_data, current_tickers, target)\n",
    "        \n",
    "#         predicted_returns, predicted_variance, actual_returns = predict_returns.loc[valid_tickers](df, start_date, next_month, opt_features, target, model)\n",
    "\n",
    "#         # logger.info(\"predict_returns function completed\")\n",
    "\n",
    "#         # 获取下一个月的股票列表\n",
    "#         current_tickers = df.loc[next_month].index.get_level_values('TICKER').tolist()\n",
    "#         # logger.info(f\"Next month stocks: {current_tickers}\")\n",
    "#         logger.info(f\"Number of stocks for next month: {len(current_tickers)}\")\n",
    "\n",
    "       \n",
    "#         logger.info(f\"Covariance matrix shape: {cov_matrix.shape}\")\n",
    "#         logger.info(f\"Predicted returns shape: {predicted_returns.shape}\")\n",
    "        \n",
    "#         if cov_matrix.shape[0] != len(predicted_returns):\n",
    "#             raise ValueError(f\"Mismatch between covariance matrix shape {cov_matrix.shape} and predicted returns length {len(predicted_returns)}\")\n",
    "\n",
    "#         optimal_weights = optimize_portfolio(predicted_returns, cov_matrix, lambda_risk_aversion)\n",
    "        \n",
    "#         # optimal_weights = optimize_portfolio(predicted_returns_aligned, cov_matrix_aligned, lambda_risk_aversion)\n",
    "\n",
    "#         if optimal_weights is None:\n",
    "#             logger.warning(\"Using equal weights due to optimization failure\")\n",
    "#             optimal_weights = np.ones(len(predicted_returns)) / len(predicted_returns)\n",
    "        \n",
    "#         logger.info(f\"Optimal weights shape: {optimal_weights.shape}\")\n",
    "        \n",
    "#         portfolio_composition = display_portfolio_composition(optimal_weights, next_month_stocks)\n",
    "#         print(f\"Portfolio Composition for {next_month.date()}:\")\n",
    "#         print(portfolio_composition)\n",
    "        \n",
    "#         monthly_rf_rate = get_risk_free_rate(featured_data, next_month)\n",
    "        \n",
    "#         monthly_portfolio_returns = np.sum(optimal_weights * actual_returns.values)\n",
    "        \n",
    "#         portfolio_return = monthly_portfolio_returns\n",
    "#         logger.info(f\"Monthly Portfolio return: {portfolio_return}\")\n",
    "        \n",
    "#         # 使用预测收益的方差来计算投资组合波动率\n",
    "#         portfolio_variance = np.sum((optimal_weights ** 2) * predicted_variance)\n",
    "#         portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "#         logger.info(f\"Monthly Portfolio volatility: {portfolio_volatility}\")\n",
    "        \n",
    "#         if portfolio_volatility > 0:\n",
    "#             monthly_sharpe_ratio = (portfolio_return - monthly_rf_rate) / portfolio_volatility\n",
    "#             annualized_sharpe_ratio = monthly_sharpe_ratio * np.sqrt(12)\n",
    "#         else:\n",
    "#             monthly_sharpe_ratio = np.nan\n",
    "#             annualized_sharpe_ratio = np.nan\n",
    "        \n",
    "#         logger.info(f\"Monthly Sharpe ratio: {monthly_sharpe_ratio}\")\n",
    "#         logger.info(f\"Annualized Sharpe ratio: {annualized_sharpe_ratio}\")\n",
    "        \n",
    "#         return portfolio_return, monthly_sharpe_ratio, mse, rmse, mae, r2\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error processing period {start_date} to {next_month}: {str(e)}\")\n",
    "#         raise\n",
    "        \n",
    "# # 使用示例：\n",
    "# date = pd.Timestamp('2017-12-31')\n",
    "# next_month = date + pd.offsets.MonthEnd(1)\n",
    "# lambda_risk_aversion = 0.5\n",
    "# portfolio_return, sharpe_ratio, mse, rmse, mae, r2 = process_single_period(opt_data, featured_data, date, next_month, opt_features, target, pipeline, lambda_risk_aversion)\n",
    "# if portfolio_return is not None and sharpe_ratio is not None:\n",
    "#     print(f\"Portfolio Return: {portfolio_return:.4f}\")\n",
    "#     print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "#     print(f\"MSE: {mse:.4f}\")\n",
    "#     print(f\"RMSE: {rmse:.4f}\")\n",
    "#     print(f\"MAE: {mae:.4f}\")\n",
    "#     print(f\"R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "442ad107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 20:52:56,805 - INFO - Processing period from 2017-12-31 00:00:00 to 2018-01-31 00:00:00\n",
      "2024-08-13 20:52:56,810 - INFO - Historical data shape: (1124, 40)\n",
      "2024-08-13 20:52:56,811 - INFO - Predicting returns from 2017-12-31 00:00:00 to 2018-01-31 00:00:00\n",
      "2024-08-13 20:52:56,812 - INFO - Train data shape: (1124, 40)\n",
      "2024-08-13 20:52:56,813 - INFO - Test data shape: (27, 40)\n",
      "2024-08-13 20:52:56,814 - INFO - X_train shape: (1124, 39)\n",
      "2024-08-13 20:52:56,815 - INFO - y_train shape: (1124, 1)\n",
      "2024-08-13 20:52:56,815 - INFO - X_test shape: (27, 39)\n",
      "2024-08-13 20:52:58,923 - INFO - Predictions shape: (27,)\n",
      "2024-08-13 20:52:58,924 - INFO - Predicted variance shape: (27,)\n",
      "2024-08-13 20:52:58,924 - INFO - actual_returns shape: (27, 1), type: <class 'pandas.core.frame.DataFrame'>\n",
      "2024-08-13 20:52:58,925 - INFO - predictions shape: (27,), type: <class 'numpy.ndarray'>\n",
      "2024-08-13 20:52:58,925 - INFO - Predicted returns shape: (27, 1)\n",
      "2024-08-13 20:52:58,926 - INFO - Predicted variance shape: (27,)\n",
      "2024-08-13 20:52:58,926 - INFO - Actual returns shape: (27, 1)\n",
      "2024-08-13 20:52:58,927 - INFO - Number of stocks for next month: 27\n",
      "2024-08-13 20:52:58,931 - INFO - estimate: valid tickers: [('RET', 'AAPL'), ('RET', 'AMZN'), ('RET', 'AXP'), ('RET', 'BAC'), ('RET', 'C'), ('RET', 'CBS'), ('RET', 'CHTR'), ('RET', 'COF'), ('RET', 'CVX'), ('RET', 'DVA'), ('RET', 'ITG'), ('RET', 'KO'), ('RET', 'KR'), ('RET', 'LPX'), ('RET', 'LUK'), ('RET', 'MA'), ('RET', 'MCO'), ('RET', 'NVR'), ('RET', 'OXY'), ('RET', 'SIRI'), ('RET', 'TMUS'), ('RET', 'V'), ('RET', 'VRSN'), ('RET', 'ALLY'), ('RET', 'ES'), ('RET', 'KHC'), ('RET', 'LSXMA')]\n",
      "/var/folders/pp/0c_n54bd7wd4nrd15cp7l12m0000gn/T/ipykernel_23571/2401183586.py:42: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  filled_data = valid_data.interpolate(method='linear', axis=0).fillna(method='ffill').fillna(method='bfill')\n",
      "2024-08-13 20:52:58,939 - INFO - Covariance matrix shape: (27, 27)\n",
      "2024-08-13 20:52:58,939 - INFO - Number of valid tickers: 27\n",
      "2024-08-13 20:52:58,940 - INFO - actual_returns is a DataFrame with shape: (27, 1)\n",
      "2024-08-13 20:52:58,944 - INFO - actual_returns_valid after filtering: (27, 1)\n",
      "2024-08-13 20:52:58,946 - INFO - Shape of predicted_returns_valid: (27, 1)\n",
      "2024-08-13 20:52:58,947 - INFO - Shape of actual_returns_valid: (27,)\n",
      "2024-08-13 20:52:58,947 - INFO - Number of valid tickers: 27\n",
      "2024-08-13 20:52:58,961 - INFO - Shape of optimal_weights: (27,)\n",
      "2024-08-13 20:52:58,966 - INFO - Portfolio Composition for 2018-01-31 00:00:00:\n",
      "2024-08-13 20:52:58,967 - INFO - Ticker  Weight\n",
      "  CHTR 100.00%\n",
      "2024-08-13 20:52:58,969 - INFO - Calculated portfolio return: 0.036169350000000024\n",
      "2024-08-13 20:52:58,972 - INFO - portfolio_volatility: 0.03685862703041853\n",
      "2024-08-13 20:52:58,974 - INFO - Annual Risk-free rate: 0.0141\n",
      "2024-08-13 20:52:58,975 - INFO - Monthly Risk-free rate: 0.0011674742711142994\n",
      "2024-08-13 20:52:58,976 - INFO - sharpe_ratio: 0.9496250552143336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio Return: 0.0362\n",
      "Sharpe Ratio: 0.9496\n",
      "MSE: 0.0004\n",
      "RMSE: 0.0188\n",
      "MAE: 0.0152\n",
      "R²: -1.1461\n",
      "\n",
      "Portfolio Composition:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# ... [其他辅助函数保持不变] ...\n",
    "\n",
    "def process_single_period(df, featured_data, start_date, next_month, opt_features, target, model, lambda_risk_aversion):\n",
    "    try:\n",
    "        logger.info(f\"Processing period from {start_date} to {next_month}\")\n",
    "        \n",
    "        historical_data = df[df.index.get_level_values('date') <= start_date]\n",
    "        logger.info(f\"Historical data shape: {historical_data.shape}\")\n",
    "        \n",
    "        # predict\n",
    "        predicted_returns, predicted_variance, actual_returns = predict_returns(df, start_date, next_month, opt_features, target, model)\n",
    "\n",
    "        logger.info(f\"Predicted returns shape: {predicted_returns.shape}\")\n",
    "        logger.info(f\"Predicted variance shape: {predicted_variance.shape}\")\n",
    "        logger.info(f\"Actual returns shape: {actual_returns.shape}\")\n",
    "        \n",
    "        if actual_returns.empty:\n",
    "            raise ValueError(\"No valid actual returns data after filtering\")\n",
    "        \n",
    "        # get ticker\n",
    "        current_tickers = df.loc[next_month].index.get_level_values('TICKER').tolist()\n",
    "        logger.info(f\"Number of stocks for next month: {len(current_tickers)}\")\n",
    "\n",
    "        # get cov based on current ticker's return\n",
    "        # logger.info(f\"process_: current tickers: {current_tickers}\")\n",
    "        cov_matrix, valid_tickers = estimate_optimal_covariance(historical_data, current_tickers, target)\n",
    "        # logger.info(f\"process_: valid tickers: {valid_tickers}\")\n",
    "        # logger.info(f\"process_: cov_matrix: {cov_matrix}\")\n",
    "\n",
    "\n",
    "        logger.info(f\"Covariance matrix shape: {cov_matrix.shape}\")\n",
    "        logger.info(f\"Number of valid tickers: {len(valid_tickers)}\")\n",
    "        \n",
    "        # 确保 predicted_returns 和 cov_matrix 使用相同的股票\n",
    "        valid_mask = np.isin(current_tickers, valid_tickers)\n",
    "        predicted_returns_valid = predicted_returns[valid_mask]\n",
    "        predicted_variance_valid = predicted_variance[valid_mask]\n",
    "        \n",
    "        # 处理 actual_returns_valid 可能是 DataFrame 的情况\n",
    "        if isinstance(actual_returns, pd.DataFrame):\n",
    "            logger.info(f\"actual_returns is a DataFrame with shape: {actual_returns.shape}\")\n",
    "            actual_returns_valid = actual_returns.loc[actual_returns.index.get_level_values('TICKER').isin(valid_tickers)]\n",
    "            logger.info(f\"actual_returns_valid after filtering: {actual_returns_valid.shape}\")\n",
    "            if actual_returns_valid.empty:\n",
    "                raise ValueError(\"No valid actual_returns_valid data after filtering\")\n",
    "            actual_returns_valid = actual_returns_valid.values.flatten()\n",
    "        else:\n",
    "            logger.info(f\"actual_returns is a numpy array with shape: {actual_returns.shape}\")\n",
    "            actual_returns_valid = actual_returns[valid_mask]\n",
    "        \n",
    "        valid_tickers = np.array(current_tickers)[valid_mask]\n",
    "        # logger.info(f\"valid_tickers: {valid_tickers}\")\n",
    "\n",
    "        logger.info(f\"Shape of predicted_returns_valid: {predicted_returns_valid.shape}\")\n",
    "        logger.info(f\"Shape of actual_returns_valid: {actual_returns_valid.shape}\")\n",
    "        logger.info(f\"Number of valid tickers: {len(valid_tickers)}\")\n",
    "\n",
    "        if len(predicted_returns_valid) == 0 or len(actual_returns_valid) == 0:\n",
    "            logger.warning(\"No valid data for this period. Skipping...\")\n",
    "            return None\n",
    "\n",
    "        if cov_matrix.shape[0] != len(predicted_returns_valid):\n",
    "            raise ValueError(f\"Mismatch between covariance matrix shape {cov_matrix.shape} and predicted returns length {len(predicted_returns_valid)}\")\n",
    "\n",
    "        optimal_weights = optimize_portfolio(predicted_returns_valid, cov_matrix, lambda_risk_aversion)\n",
    "        \n",
    "        logger.info(f\"Shape of optimal_weights: {optimal_weights.shape}\")\n",
    "        # logger.info(f\"optimal_weights: {optimal_weights}\")\n",
    "\n",
    "        # 显示投资组合构成\n",
    "        portfolio_composition, portfolio_str = display_portfolio_composition(optimal_weights, valid_tickers)\n",
    "        logger.info(f\"Portfolio Composition for {next_month}:\")\n",
    "        logger.info(portfolio_str)\n",
    "\n",
    "        portfolio_return = np.dot(optimal_weights , predicted_returns_valid).item()\n",
    "        logger.info(f\"Calculated portfolio return: {portfolio_return}\")\n",
    "\n",
    "        # portfolio_volatility = np.sqrt(np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights)))\n",
    "        portfolio_volatility = np.sqrt(np.dot(optimal_weights, predicted_variance_valid).item())\n",
    "        logger.info(f\"portfolio_volatility: {portfolio_volatility}\")\n",
    "\n",
    "        rf_rate = get_risk_free_rate(featured_data, next_month)\n",
    "        \n",
    "        sharpe_ratio = (portfolio_return - rf_rate) / portfolio_volatility #if portfolio_volatility > 0 else np.nan\n",
    "        logger.info(f\"sharpe_ratio: {sharpe_ratio}\")\n",
    "\n",
    "        mse, rmse, mae, r2 = calculate_model_metrics(actual_returns_valid, predicted_returns_valid)\n",
    "        \n",
    "        # print(portfolio_composition.to_string(index=False))\n",
    "\n",
    "        return portfolio_return, sharpe_ratio, mse, rmse, mae, r2\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing period {start_date} to {next_month}: {str(e)}\")\n",
    "        logger.error(f\"Error details: {str(e)}\", exc_info=True)\n",
    "        return None\n",
    "\n",
    "# 使用示例\n",
    "date = pd.Timestamp('2017-12-31')\n",
    "next_month = date + pd.offsets.MonthEnd(1)\n",
    "lambda_risk_aversion = 0.9\n",
    "\n",
    "result = process_single_period(opt_data, featured_data, date, next_month, opt_features, target, pipeline, lambda_risk_aversion)\n",
    "\n",
    "if result is not None:\n",
    "    portfolio_return, sharpe_ratio, mse, rmse, mae, r2 = result\n",
    "    print(f\"Portfolio Return: {portfolio_return:.4f}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(\"\\nPortfolio Composition:\")\n",
    "else:\n",
    "    print(\"No valid data for this period.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "5879d8bc-fdb9-4b08-97f0-0189792a7248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_portfolio_optimization(opt_data, featured_data, start_date, end_date, features, target, model, lambda_risk_aversion, window_size):\n",
    "    dates = pd.date_range(start_date, end_date, freq='M')\n",
    "    portfolio_returns = []\n",
    "    sharpe_ratios = []\n",
    "    mses = []\n",
    "    rmses = []\n",
    "    maes = []\n",
    "    r2s = []\n",
    "\n",
    "    for i in range(len(dates) - window_size):\n",
    "        train_start = dates[i]\n",
    "        train_end = dates[i + window_size - 1]\n",
    "        next_month = dates[i + window_size]\n",
    "        \n",
    "        logger.info(f\"Training from {train_start} to {train_end}, predicting for {next_month}\")\n",
    "        \n",
    "        # 训练模型\n",
    "        train_data = get_data_for_date_range(opt_data, train_start, train_end)\n",
    "        X_train, y_train = prepare_training_data(train_data, features, target)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # 处理单个时期并计算投资组合回报率和夏普比率\n",
    "        portfolio_return, sharpe_ratio, mse, rmse, mae, r2 = process_single_period(opt_data, featured_data, train_end, next_month, features, target, model, lambda_risk_aversion)\n",
    "        portfolio_returns.append(portfolio_return)\n",
    "        sharpe_ratios.append(sharpe_ratio)\n",
    "        mses.append(mse)\n",
    "        rmses.append(rmse)\n",
    "        maes.append(mae)\n",
    "        r2s.append(r2)\n",
    "        \n",
    "    \n",
    "    return portfolio_returns, sharpe_ratios, mses, rmses, maes, r2s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "71c54c43-89b4-451b-ab8d-6b6f333f102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pp/0c_n54bd7wd4nrd15cp7l12m0000gn/T/ipykernel_23571/1559073234.py:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  dates = pd.date_range(start_date, end_date, freq='M')\n",
      "2024-08-13 20:53:10,654 - INFO - Training from 2015-10-31 00:00:00 to 2016-09-30 00:00:00, predicting for 2016-10-31 00:00:00\n",
      "2024-08-13 20:53:11,070 - INFO - Processing period from 2016-09-30 00:00:00 to 2016-10-31 00:00:00\n",
      "2024-08-13 20:53:11,071 - INFO - Historical data shape: (713, 40)\n",
      "2024-08-13 20:53:11,071 - INFO - Predicting returns from 2016-09-30 00:00:00 to 2016-10-31 00:00:00\n",
      "2024-08-13 20:53:11,072 - INFO - Train data shape: (713, 40)\n",
      "2024-08-13 20:53:11,073 - INFO - Test data shape: (27, 40)\n",
      "2024-08-13 20:53:11,074 - INFO - X_train shape: (713, 39)\n",
      "2024-08-13 20:53:11,074 - INFO - y_train shape: (713, 1)\n",
      "2024-08-13 20:53:11,074 - INFO - X_test shape: (27, 39)\n",
      "2024-08-13 20:53:12,073 - INFO - Predictions shape: (27,)\n",
      "2024-08-13 20:53:12,074 - INFO - Predicted variance shape: (27,)\n",
      "2024-08-13 20:53:12,074 - INFO - actual_returns shape: (27, 1), type: <class 'pandas.core.frame.DataFrame'>\n",
      "2024-08-13 20:53:12,075 - INFO - predictions shape: (27,), type: <class 'numpy.ndarray'>\n",
      "2024-08-13 20:53:12,076 - INFO - Predicted returns shape: (27, 1)\n",
      "2024-08-13 20:53:12,076 - INFO - Predicted variance shape: (27,)\n",
      "2024-08-13 20:53:12,076 - INFO - Actual returns shape: (27, 1)\n",
      "2024-08-13 20:53:12,077 - INFO - Number of stocks for next month: 27\n",
      "2024-08-13 20:53:12,081 - INFO - estimate: valid tickers: [('RET', 'AAPL'), ('RET', 'AMZN'), ('RET', 'AXP'), ('RET', 'BAC'), ('RET', 'C'), ('RET', 'CBS'), ('RET', 'CHTR'), ('RET', 'COF'), ('RET', 'CVX'), ('RET', 'DVA'), ('RET', 'ITG'), ('RET', 'KO'), ('RET', 'KR'), ('RET', 'LPX'), ('RET', 'LUK'), ('RET', 'MA'), ('RET', 'MCO'), ('RET', 'NVR'), ('RET', 'OXY'), ('RET', 'SIRI'), ('RET', 'TMUS'), ('RET', 'V'), ('RET', 'VRSN'), ('RET', 'SNOW'), ('RET', 'ALLY'), ('RET', 'ES'), ('RET', 'KHC')]\n",
      "/var/folders/pp/0c_n54bd7wd4nrd15cp7l12m0000gn/T/ipykernel_23571/2401183586.py:42: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  filled_data = valid_data.interpolate(method='linear', axis=0).fillna(method='ffill').fillna(method='bfill')\n",
      "2024-08-13 20:53:12,089 - INFO - Covariance matrix shape: (27, 27)\n",
      "2024-08-13 20:53:12,093 - INFO - Number of valid tickers: 27\n",
      "2024-08-13 20:53:12,095 - INFO - actual_returns is a DataFrame with shape: (27, 1)\n",
      "2024-08-13 20:53:12,098 - INFO - actual_returns_valid after filtering: (27, 1)\n",
      "2024-08-13 20:53:12,100 - INFO - Shape of predicted_returns_valid: (27, 1)\n",
      "2024-08-13 20:53:12,100 - INFO - Shape of actual_returns_valid: (27,)\n",
      "2024-08-13 20:53:12,101 - INFO - Number of valid tickers: 27\n",
      "2024-08-13 20:53:12,146 - INFO - Shape of optimal_weights: (27,)\n",
      "2024-08-13 20:53:12,154 - INFO - Portfolio Composition for 2016-10-31 00:00:00:\n",
      "2024-08-13 20:53:12,155 - INFO - Ticker Weight\n",
      "  ALLY 82.84%\n",
      "   COF 17.16%\n",
      "2024-08-13 20:53:12,156 - INFO - Calculated portfolio return: 0.009124520964817936\n",
      "2024-08-13 20:53:12,157 - INFO - portfolio_volatility: 0.022226253476914697\n",
      "2024-08-13 20:53:12,160 - INFO - Annual Risk-free rate: 0.0033\n",
      "2024-08-13 20:53:12,163 - INFO - Monthly Risk-free rate: 0.0002745849373302356\n",
      "2024-08-13 20:53:12,166 - INFO - sharpe_ratio: 0.3981748897392756\n",
      "2024-08-13 20:53:12,171 - INFO - Training from 2015-11-30 00:00:00 to 2016-10-31 00:00:00, predicting for 2016-11-30 00:00:00\n",
      "2024-08-13 20:53:12,678 - INFO - Processing period from 2016-10-31 00:00:00 to 2016-11-30 00:00:00\n",
      "2024-08-13 20:53:12,679 - INFO - Historical data shape: (740, 40)\n",
      "2024-08-13 20:53:12,679 - INFO - Predicting returns from 2016-10-31 00:00:00 to 2016-11-30 00:00:00\n",
      "2024-08-13 20:53:12,681 - INFO - Train data shape: (740, 40)\n",
      "2024-08-13 20:53:12,681 - INFO - Test data shape: (27, 40)\n",
      "2024-08-13 20:53:12,683 - INFO - X_train shape: (740, 39)\n",
      "2024-08-13 20:53:12,684 - INFO - y_train shape: (740, 1)\n",
      "2024-08-13 20:53:12,684 - INFO - X_test shape: (27, 39)\n",
      "2024-08-13 20:53:13,923 - INFO - Predictions shape: (27,)\n",
      "2024-08-13 20:53:13,923 - INFO - Predicted variance shape: (27,)\n",
      "2024-08-13 20:53:13,924 - INFO - actual_returns shape: (27, 1), type: <class 'pandas.core.frame.DataFrame'>\n",
      "2024-08-13 20:53:13,924 - INFO - predictions shape: (27,), type: <class 'numpy.ndarray'>\n",
      "2024-08-13 20:53:13,925 - INFO - Predicted returns shape: (27, 1)\n",
      "2024-08-13 20:53:13,925 - INFO - Predicted variance shape: (27,)\n",
      "2024-08-13 20:53:13,925 - INFO - Actual returns shape: (27, 1)\n",
      "2024-08-13 20:53:13,926 - INFO - Number of stocks for next month: 27\n",
      "2024-08-13 20:53:13,929 - INFO - estimate: valid tickers: [('RET', 'AAPL'), ('RET', 'AMZN'), ('RET', 'AXP'), ('RET', 'BAC'), ('RET', 'C'), ('RET', 'CBS'), ('RET', 'CHTR'), ('RET', 'COF'), ('RET', 'CVX'), ('RET', 'DVA'), ('RET', 'ITG'), ('RET', 'KO'), ('RET', 'KR'), ('RET', 'LPX'), ('RET', 'LUK'), ('RET', 'MA'), ('RET', 'MCO'), ('RET', 'NVR'), ('RET', 'OXY'), ('RET', 'SIRI'), ('RET', 'TMUS'), ('RET', 'V'), ('RET', 'VRSN'), ('RET', 'SNOW'), ('RET', 'ALLY'), ('RET', 'ES'), ('RET', 'KHC')]\n",
      "/var/folders/pp/0c_n54bd7wd4nrd15cp7l12m0000gn/T/ipykernel_23571/2401183586.py:42: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  filled_data = valid_data.interpolate(method='linear', axis=0).fillna(method='ffill').fillna(method='bfill')\n",
      "2024-08-13 20:53:13,934 - INFO - Covariance matrix shape: (27, 27)\n",
      "2024-08-13 20:53:13,935 - INFO - Number of valid tickers: 27\n",
      "2024-08-13 20:53:13,936 - INFO - actual_returns is a DataFrame with shape: (27, 1)\n",
      "2024-08-13 20:53:13,938 - INFO - actual_returns_valid after filtering: (27, 1)\n",
      "2024-08-13 20:53:13,939 - INFO - Shape of predicted_returns_valid: (27, 1)\n",
      "2024-08-13 20:53:13,940 - INFO - Shape of actual_returns_valid: (27,)\n",
      "2024-08-13 20:53:13,940 - INFO - Number of valid tickers: 27\n",
      "2024-08-13 20:53:13,959 - INFO - Shape of optimal_weights: (27,)\n",
      "2024-08-13 20:53:13,963 - INFO - Portfolio Composition for 2016-11-30 00:00:00:\n",
      "2024-08-13 20:53:13,964 - INFO - Ticker Weight\n",
      "   LPX 53.90%\n",
      "   LUK 46.10%\n",
      "2024-08-13 20:53:13,965 - INFO - Calculated portfolio return: 0.01640315088889566\n",
      "2024-08-13 20:53:13,967 - INFO - portfolio_volatility: 0.02324046375739969\n",
      "2024-08-13 20:53:13,968 - INFO - Annual Risk-free rate: 0.0045000000000000005\n",
      "2024-08-13 20:53:13,968 - INFO - Monthly Risk-free rate: 0.00037422877886217343\n",
      "2024-08-13 20:53:13,968 - INFO - sharpe_ratio: 0.6896988923007153\n",
      "2024-08-13 20:53:13,970 - INFO - Training from 2015-12-31 00:00:00 to 2016-11-30 00:00:00, predicting for 2016-12-31 00:00:00\n",
      "2024-08-13 20:53:14,413 - INFO - Processing period from 2016-11-30 00:00:00 to 2016-12-31 00:00:00\n",
      "2024-08-13 20:53:14,414 - INFO - Historical data shape: (767, 40)\n",
      "2024-08-13 20:53:14,414 - INFO - Predicting returns from 2016-11-30 00:00:00 to 2016-12-31 00:00:00\n",
      "2024-08-13 20:53:14,416 - INFO - Train data shape: (767, 40)\n",
      "2024-08-13 20:53:14,416 - INFO - Test data shape: (27, 40)\n",
      "2024-08-13 20:53:14,417 - INFO - X_train shape: (767, 39)\n",
      "2024-08-13 20:53:14,417 - INFO - y_train shape: (767, 1)\n",
      "2024-08-13 20:53:14,417 - INFO - X_test shape: (27, 39)\n",
      "2024-08-13 20:53:15,556 - INFO - Predictions shape: (27,)\n",
      "2024-08-13 20:53:15,557 - INFO - Predicted variance shape: (27,)\n",
      "2024-08-13 20:53:15,557 - INFO - actual_returns shape: (27, 1), type: <class 'pandas.core.frame.DataFrame'>\n",
      "2024-08-13 20:53:15,558 - INFO - predictions shape: (27,), type: <class 'numpy.ndarray'>\n",
      "2024-08-13 20:53:15,558 - INFO - Predicted returns shape: (27, 1)\n",
      "2024-08-13 20:53:15,558 - INFO - Predicted variance shape: (27,)\n",
      "2024-08-13 20:53:15,558 - INFO - Actual returns shape: (27, 1)\n",
      "2024-08-13 20:53:15,559 - INFO - Number of stocks for next month: 27\n",
      "2024-08-13 20:53:15,561 - INFO - estimate: valid tickers: [('RET', 'AAPL'), ('RET', 'AMZN'), ('RET', 'AXP'), ('RET', 'BAC'), ('RET', 'C'), ('RET', 'CBS'), ('RET', 'CHTR'), ('RET', 'COF'), ('RET', 'CVX'), ('RET', 'DVA'), ('RET', 'ITG'), ('RET', 'KO'), ('RET', 'KR'), ('RET', 'LPX'), ('RET', 'LUK'), ('RET', 'MA'), ('RET', 'MCO'), ('RET', 'NVR'), ('RET', 'OXY'), ('RET', 'SIRI'), ('RET', 'TMUS'), ('RET', 'V'), ('RET', 'VRSN'), ('RET', 'SNOW'), ('RET', 'ALLY'), ('RET', 'ES'), ('RET', 'KHC')]\n",
      "/var/folders/pp/0c_n54bd7wd4nrd15cp7l12m0000gn/T/ipykernel_23571/2401183586.py:42: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  filled_data = valid_data.interpolate(method='linear', axis=0).fillna(method='ffill').fillna(method='bfill')\n",
      "2024-08-13 20:53:15,566 - INFO - Covariance matrix shape: (27, 27)\n",
      "2024-08-13 20:53:15,567 - INFO - Number of valid tickers: 27\n",
      "2024-08-13 20:53:15,567 - INFO - actual_returns is a DataFrame with shape: (27, 1)\n",
      "2024-08-13 20:53:15,568 - INFO - actual_returns_valid after filtering: (27, 1)\n",
      "2024-08-13 20:53:15,569 - INFO - Shape of predicted_returns_valid: (27, 1)\n",
      "2024-08-13 20:53:15,569 - INFO - Shape of actual_returns_valid: (27,)\n",
      "2024-08-13 20:53:15,570 - INFO - Number of valid tickers: 27\n",
      "2024-08-13 20:53:15,592 - INFO - Shape of optimal_weights: (27,)\n",
      "2024-08-13 20:53:15,594 - INFO - Portfolio Composition for 2016-12-31 00:00:00:\n",
      "2024-08-13 20:53:15,594 - INFO - Ticker  Weight\n",
      "   OXY 100.00%\n",
      "Others   0.00%\n",
      "2024-08-13 20:53:15,594 - INFO - Calculated portfolio return: 0.02638218\n",
      "2024-08-13 20:53:15,595 - INFO - portfolio_volatility: 0.030243219511612848\n",
      "2024-08-13 20:53:15,596 - INFO - Annual Risk-free rate: 0.0051\n",
      "2024-08-13 20:53:15,597 - INFO - Monthly Risk-free rate: 0.0004240097874610438\n",
      "2024-08-13 20:53:15,598 - INFO - sharpe_ratio: 0.8583137189667089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sharpe Ratio: 0.6487291670022334\n",
      "Average MSE: 0.0003617884602123877\n",
      "Average RMSE: 0.018491753016163157\n",
      "Average MAE: 0.0141453012345679\n",
      "Average R2: -1.0021433702474345\n"
     ]
    }
   ],
   "source": [
    "# 使用示例：\n",
    "start_date = pd.Timestamp('2015-10-31')\n",
    "end_date = pd.Timestamp('2016-12-31')\n",
    "# start_date = opt_data.index.get_level_values('date').min()\n",
    "# end_date = opt_data.index.get_level_values('date').max()\n",
    "\n",
    "lambda_risk_aversion = 0.9\n",
    "window_size = 12  # 每个持有期为12个月\n",
    "\n",
    "portfolio_returns, sharpe_ratios, mses, rmses, maes, r2s = rolling_portfolio_optimization(opt_data, featured_data, start_date, end_date, opt_features, target, pipeline, lambda_risk_aversion, window_size)\n",
    "\n",
    "\n",
    "# 计算平均夏普比率\n",
    "average_sharpe_ratio = np.mean(sharpe_ratios)\n",
    "print(f\"Average Sharpe Ratio: {average_sharpe_ratio}\")\n",
    "\n",
    "print(f\"Average MSE: {np.mean(mses)}\")\n",
    "print(f\"Average RMSE: {np.mean(rmses)}\")\n",
    "print(f\"Average MAE: {np.mean(maes)}\")\n",
    "print(f\"Average R2: {np.mean(r2s)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64502e77-01d6-429f-9ddb-93ce53d94af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
