{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import missingno as msno  # missingno库提供了一个很好的可视化缺失数据的方式\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler, PowerTransformer, QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_financial_stock_macro_data_with_better_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = final_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保数据按 TICKER 和 date 排序\n",
    "df = df.sort_values(['TICKER', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)\n",
    "\n",
    "df.set_index(['date'], inplace=True)\n",
    "\n",
    "def dropIndex(dataset):\n",
    "    try:\n",
    "        dataset = dataset.drop(columns = ['level_0', 'index'])\n",
    "    except Exception as e:\n",
    "                print(f\"Issue : {e}\")\n",
    "    return dataset\n",
    "df = dropIndex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing_vars = [\n",
    "#     'market_cap',  # ME (Market Equity)\n",
    "#     'bm',          # Book-to-Market\n",
    "#     'pe_op_basic', # E2P (inverse)\n",
    "#     'pe_op_dil',   # Another version of E2P (inverse)\n",
    "#     'npm',         # Similar to PM (Profit Margin)\n",
    "#     'gpm',         # Similar to PCM (Price-to-Cost Margin)\n",
    "#     'roa',         # Return on Assets\n",
    "#     'roe',         # Return on Equity\n",
    "#     'ps',          # Price to Sales (inverse of S2P)\n",
    "#     'debt_assets', # Similar to Lev (Leverage)\n",
    "#     'at_turn',     # Similar to ATO (Asset Turnover)\n",
    "#     'accrual',     # Might correspond to OA (Operating Accruals)\n",
    "#     'divyield',    # Dividend Yield\n",
    "# ]\n",
    "benchmark = ['Size','Momentum','bm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Green et al. (2017)的94个指标部分\n",
    "Welch and Goyal (2008) 宏观指标：Treasury-bill rate (tbl), term spread (tms), default spread (dfy)\n",
    "\n",
    "市场相关指标:\n",
    "\n",
    "\n",
    "ME (Market Equity): 公司层面的总市值\n",
    "LME: 上个月月末的总市值\n",
    "LTurnover: 上月总交易量与上月月末总市值的比率\n",
    "Spread: 上月日均买卖价差\n",
    "Beta: 根据Frazzini和Pedersen (2014)的定义计算的贝塔值\n",
    "Idio vol (Idiosyncratic Volatility): 基于Ang等(2006)方法计算的特异波动率\n",
    "\n",
    "\n",
    "\n",
    "历史回报指标:\n",
    "\n",
    "\n",
    "r2−1: 上个月的滞后回报\n",
    "r12−2: 过去12个月(不包括最后一个月)的回报\n",
    "r12−7: 中期动量(过去12个月到过去7个月的回报)\n",
    "r36−13: 长期回报(3年前到去年的回报)\n",
    "\n",
    "\n",
    "财务报表指标:\n",
    "\n",
    "\n",
    "BE (Book Equity): 账面权益\n",
    "BM (Book-to-Market): 账面市值比\n",
    "AT: 总资产\n",
    "ATO: 销售额除以净营运资产\n",
    "C (Cash): 现金和短期投资占总资产比例\n",
    "CTO: 资本周转率\n",
    "D2A: 折旧和摊销占总资产比例\n",
    "DPI2A: 固定资产变动\n",
    "E2P: 市盈率的倒数\n",
    "FC2Y: 费用销售比(广告、研发、销售管理费用总和除以销售额)\n",
    "Free CF: 自由现金流\n",
    "Investment: 总资产增长率\n",
    "Lev: 杠杆率(总债务/(总债务+股东权益))\n",
    "NOA: 净营运资产占滞后总资产比例\n",
    "OA: 营运应计项目(根据Sloan (1996)定义)\n",
    "OL: 营运杠杆(销货成本和销售管理费用除以总资产)\n",
    "PCM: 价格成本利润率((销售额-销货成本)/销售额)\n",
    "PM: 营业利润率(折旧后营业收入/净销售额)\n",
    "Prof: 毛利润率(毛利润/权益账面价值)\n",
    "Q: 托宾Q值\n",
    "Rel to high: 接近52周最高价的程度\n",
    "RNA: 净营运资产回报率\n",
    "ROA: 资产回报率(税前利润/总资产)\n",
    "ROE: 权益回报率(税前利润/滞后权益账面价值)\n",
    "S2P: 销售额市值比\n",
    "SGA2S: 销售管理费用率(销售管理费用/净销售额)\n",
    "SUV: 标准化非预期交易量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据Gu 2020年的论文，我们可以将特征分为以下几类：\n",
    "\n",
    "基准特征（3个）：\n",
    "\n",
    "规模（Size）\n",
    "账面市值比（Book-to-Market ratio）\n",
    "动量（Momentum）\n",
    "\n",
    "\n",
    "股票水平预测器（主要分为三类）：\n",
    "a. 价格趋势变量：\n",
    "\n",
    "股票动量\n",
    "行业动量\n",
    "短期反转\n",
    "b. 流动性变量：\n",
    "市值\n",
    "美元交易量\n",
    "买卖价差\n",
    "c. 波动性相关：\n",
    "回报波动率\n",
    "特质波动率\n",
    "市场beta\n",
    "beta平方\n",
    "\n",
    "\n",
    "宏观经济预测器（8个）：\n",
    "\n",
    "股息-价格比（Dividend-Price Ratio, dp）\n",
    "收益-价格比（Earnings-Price Ratio, ep）\n",
    "账面市值比（Book-to-Market Ratio, bm）\n",
    "净股票发行（Net Equity Expansion, ntis）\n",
    "国库券利率（Treasury-bill Rate, tbl）\n",
    "期限利差（Term Spread, tms）\n",
    "违约利差（Default Spread, dfy）\n",
    "股票方差（Stock Variance, svar）\n",
    "\n",
    "\n",
    "94个预测特征（基于Green et al. (2017)）\n",
    "\n",
    "处理步骤：\n",
    "\n",
    "基准特征和主要股票水平预测器：\n",
    "这些特征大多可以从CRSP数据中直接计算或提取。\n",
    "宏观经济预测器：\n",
    "这些需要额外的宏观经济数据源，可能需要从Federal Reserve Economic Data (FRED)或其他经济数据库获取。\n",
    "94个预测特征：\n",
    "这些特征基于Green et al. (2017)，需要使用财务报表数据（如Compustat）结合市场数据来计算。\n",
    "数据对齐：\n",
    "\n",
    "月度特征：使用t月末的数据预测t+1月的回报\n",
    "季度特征：使用至少4个月前的数据\n",
    "年度特征：使用至少6个月前的数据\n",
    "\n",
    "\n",
    "处理缺失值：\n",
    "对于缺失的特征，使用每个月每只股票的横截面中位数进行填充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据您提供的信息，我将帮您整理需要的变量、已有的变量和缺失的变量。\n",
    "\n",
    "1. 需要的变量（基于您的要求）：\n",
    "\n",
    "a. 基准特征：\n",
    "   - Size (已有)\n",
    "   - Book-to-Market ratio (已有，对应 'bm')\n",
    "   - Momentum (已有)\n",
    "\n",
    "b. 股票水平预测器：\n",
    "   - 股票动量 (已有，对应 'Momentum')\n",
    "   - 行业动量 (缺失)\n",
    "   - 短期反转 (已有，对应 'ShortTermReversal')\n",
    "   - 市值 (已有，对应 'ME' 或 'market_cap')\n",
    "   - 美元交易量 (已有，对应 'DollarVolume')\n",
    "   - 买卖价差 (已有，对应 'spread')\n",
    "   - 回报波动率 (可以从 'RET' 计算)\n",
    "   - 特质波动率 (已有，对应 'Idio_vol')\n",
    "   - 市场beta (已有，对应 'Beta')\n",
    "   - beta平方 (已有，对应 'BetaSquared')\n",
    "\n",
    "c. 宏观经济预测器：\n",
    "   - 股息-价格比 (dp) (已有，对应 'divyield')\n",
    "   - 收益-价格比 (ep) (可以从 'pe_op_basic' 或 'pe_op_dil' 的倒数得到)\n",
    "   - 账面市值比 (bm) (已有)\n",
    "   - 净股票发行 (ntis) (缺失)\n",
    "   - 国库券利率 (tbl) (可能对应 'TB3MS'，需确认)\n",
    "   - 期限利差 (tms) (可能对应 'T10Y2Y'，需确认)\n",
    "   - 违约利差 (dfy) (可能对应 'BAA10Y'，需确认)\n",
    "   - 股票方差 (svar) (可以从 'RET' 计算)\n",
    "\n",
    "2. 已有的重要变量（除上述外）：\n",
    "   - 'roa', 'roe', 'roce' (盈利能力指标)\n",
    "   - 'debt_assets', 'debt_capital', 'de_ratio' (杠杆指标)\n",
    "   - 'cash_ratio', 'quick_ratio', 'curr_ratio' (流动性指标)\n",
    "   - 'at_turn', 'inv_turn' (效率指标)\n",
    "   - 'accrual' (质量指标)\n",
    "   - 'PRC', 'VOL', 'SHROUT' (价格、交易量、股数)\n",
    "   - 'vwretd', 'ewretd', 'sprtrn' (市场回报指标)\n",
    "\n",
    "3. 缺失的重要变量：\n",
    "   - 行业动量\n",
    "   - 净股票发行 (ntis)\n",
    "\n",
    "4. 可能不需要的变量（这取决于您的具体研究目的，但这些变量可能与其他变量重复或不太常用）：\n",
    "   - 'CAPEI' (如果有 'pe_op_basic' 或 'pe_op_dil')\n",
    "   - 'evm' (如果已有 'bm')\n",
    "   - 'pe_exi', 'pe_inc' (如果已有 'pe_op_basic' 或 'pe_op_dil')\n",
    "   - 'ptpm' (如果已有 'npm')\n",
    "   - 'pcf' (如果已有 'ps' 和 'cfm')\n",
    "   - 'aftret_eq', 'aftret_invcapx', 'aftret_equity' (如果已有 'roe' 和 'roce')\n",
    "   - 'pretret_noa', 'pretret_earnat' (如果已有其他盈利能力指标)\n",
    "   - 'equity_invcap', 'debt_invcap', 'totdebt_invcap' (如果已有 'debt_capital' 和 'de_ratio')\n",
    "   - 'intcov', 'intcov_ratio' (可能重复)\n",
    "   - 'sale_invcap', 'sale_equity', 'sale_nwc' (如果已有 'ps' 和其他效率指标)\n",
    "   - 'int_debt', 'int_totdebt' (如果已有其他债务指标)\n",
    "   - 'invt_act', 'rect_act' (如果已有 'curr_ratio' 和 'quick_ratio')\n",
    "   - 'short_debt', 'curr_debt', 'lt_debt' (如果已有 'debt_assets' 和 'debt_capital')\n",
    "   - 'ptb' (如果已有 'bm')\n",
    "   - 'PEG_trailing' (如果已有 'pe_op_basic' 或 'pe_op_dil' 和增长率指标)\n",
    "\n",
    "对于缺失的变量和需要计算的变量，您可能需要获取额外的数据或使用现有数据进行计算。例如，行业动量可能需要行业分类数据，而回报波动率和股票方差可以使用现有的回报数据计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_variables(df):\n",
    "    # 0 benchmark\n",
    "    df['BM'] = df['bm']\n",
    "    \n",
    "    # ME (Market Equity)\n",
    "    df['ME'] = df['market_cap']\n",
    "    # Size (natural log of ME)\n",
    "    df['Size'] = np.log(df['ME'])\n",
    "    \n",
    "    # Momentum (11-month return, 1 month ago)\n",
    "    def calculate_momentum(group):\n",
    "        return group.rolling(window=11).apply(lambda x: (1 + x).prod() - 1).shift(1)\n",
    "\n",
    "    df['Momentum'] = df.groupby('TICKER')['RET'].transform(calculate_momentum)\n",
    "\n",
    "    # 1 市场相关指标\n",
    "    # 短期反转（过去1个月的回报）\n",
    "    df['ShortTermReversal'] = df.groupby('TICKER')['RET'].shift(1)\n",
    "    \n",
    "    # # 计算市值\n",
    "    # df['market_cap'] = df['PRC'].abs() * df['SHROUT']\n",
    "    \n",
    "    # # LME (Lagged Market Equity) 上个月月末的总市值\n",
    "    # df['LME'] = df.groupby('TICKER')['market_cap'].shift(1)\n",
    "    \n",
    "    # # LTurnover 上月总交易量与上月月末总市值的比率\n",
    "    # df['LTurnover'] = df['VOL'] / df['LME']\n",
    "    \n",
    "    # # 美元交易量\n",
    "    # df['DollarVolume'] = df['PRC'].abs() * df['VOL']\n",
    "\n",
    "    # # Spread 上月日均买卖价差\n",
    "    # df['spread'] = (df['ASKHI'] - df['BIDLO']) / ((df['ASKHI'] + df['BIDLO']) / 2)\n",
    "    \n",
    "    # # 计算20天滚动标准差\n",
    "    # df['Volatility'] = df.groupby('TICKER')['RET'].transform(lambda x: x.rolling(window=20, min_periods=1).std())\n",
    "    # # 处理可能的 NaN 值\n",
    "    # df['Volatility'] = df['Volatility'].fillna(0)\n",
    "\n",
    "    # 重置索引\n",
    "    # df_reset = df.reset_index()\n",
    "    \n",
    "    # # Beta (simplified version) 用滚动算\n",
    "    # def calculate_beta(stock_returns, market_returns, window=52):\n",
    "    #     return stock_returns.rolling(window=window).apply(lambda x: np.cov(x, market_returns[-window:])[0,1] / np.var(market_returns[-window:]))\n",
    "    \n",
    "    # df_reset['Beta'] = df.groupby('TICKER')['RET'].apply(lambda x: calculate_beta(x, df['sprtrn']))\n",
    "\n",
    "    # # 计算Beta平方\n",
    "    # df_reset['BetaSquared'] = df_reset['Beta'] ** 2\n",
    "\n",
    "    # df['Beta'] = df_reset['Beta']\n",
    "    # df['BetaSquared'] = df_reset['BetaSquared']\n",
    "\n",
    "\n",
    "    # 2 历史回报指标\n",
    "    # # Historical returns\n",
    "    # df['r2_1'] = df.groupby('TICKER')['RET'].shift(1)\n",
    "\n",
    "    # # 计算 r12_2\n",
    "    # df_reset['r12_2'] = df_reset.groupby('TICKER')['RET'].rolling(window=11).sum().shift(1).reset_index(0, drop=True)\n",
    "    # df_reset['r12_7'] = df_reset.groupby('TICKER')['RET'].rolling(window=6).sum().shift(6).reset_index(0, drop=True)\n",
    "    # df_reset['r36_13'] = df_reset.groupby('TICKER')['RET'].rolling(window=24).sum().shift(12).reset_index(0, drop=True)\n",
    "\n",
    "    # # 设置回原来的索引\n",
    "    # df_reset.set_index('index', inplace=True)\n",
    "    \n",
    "    # # 将结果赋值给原始 DataFrame\n",
    "    # df['r12_2'] = df_reset['r12_2']\n",
    "    # df['r12_7'] = df_reset['r12_7']\n",
    "    # df['r36_13'] = df_reset['r36_13']\n",
    "\n",
    "    # df['RET_lag_1_mon'] = df.groupby('TICKER')['RET'].shift(1)\n",
    "\n",
    "    # 3 财务报表指标\n",
    "    \n",
    "    # # 重置索引\n",
    "    # df_reset = df.reset_index()\n",
    "    \n",
    "    # # 确保 'DATE' 列是 datetime 类型\n",
    "    # df_reset['date'] = pd.to_datetime(df_reset['date'])\n",
    "    \n",
    "    # # 设置 'DATE' 列为索引\n",
    "    # df_reset.set_index('date', inplace=True)\n",
    "    \n",
    "    # # 确保索引是升序排列的\n",
    "    # df_reset.sort_index(inplace=True)\n",
    "\n",
    "    # # Rel to high 接近52周最高价的程度\n",
    "    # df_reset['52_week_high'] = df_reset.groupby('TICKER')['PRC'].rolling(window=52).max().reset_index(0, drop=True)\n",
    "    \n",
    "    # # 计算 Rel_to_high\n",
    "    # df_reset['Rel_to_high'] = df_reset['PRC'] / df_reset['52_week_high']\n",
    "    \n",
    "    # 设置回原来的索引\n",
    "    # df_reset.set_index('index', inplace=True)\n",
    "    # print(df_reset['52_week_high'].isnull().sum())\n",
    "    \n",
    "    # # 将结果赋值给原始 DataFrame\n",
    "    # df['52_week_high'] = df_reset['52_week_high']\n",
    "    # df['Rel_to_high'] = df_reset['Rel_to_high']\n",
    "    \n",
    "    # SUV (Standardized Unexplained Volume)\n",
    "    # def calculate_suv(volume, window=20):\n",
    "    #     log_volume = np.log(volume)\n",
    "    #     mean_log_volume = log_volume.rolling(window=window).mean()\n",
    "    #     std_log_volume = log_volume.rolling(window=window).std()\n",
    "    #     return (log_volume - mean_log_volume) / std_log_volume\n",
    "    \n",
    "    # df['SUV'] = df.groupby('TICKER')['VOL'].apply(calculate_suv)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to your dataframe\n",
    "df = calculate_variables(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算缺失值统计，转换为 DataFrame\n",
    "null_summary = pd.DataFrame(df.isnull().sum(), columns=['MissingValueCount'])\n",
    "\n",
    "# 使用 option_context 临时改变显示设置并直接显示 DataFrame\n",
    "with pd.option_context('display.max_columns', None,  'display.max_colwidth', 20):\n",
    "    display(null_summary)\n",
    "\n",
    "null_summary.to_csv(\"missing_value_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理无穷大和NaN值\n",
    "df = df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_fill_numeric(df, var):\n",
    "    # 尝试将数据转换为数值型\n",
    "    df[var] = pd.to_numeric(df[var], errors='coerce')    \n",
    "    return df\n",
    "    \n",
    "# 对每个需要处理的变量应用此函数\n",
    "variables_to_clean = ['Momentum', 'r12_2', 'r12_7', 'r36_13', 'sprtrn', 'RET', 'RET_lag_1_mon']  # 添加所有需要处理的变量\n",
    "for var in variables_to_clean:\n",
    "    df = clean_and_fill_numeric(df, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    # 对历史回报指标使用前向填充\n",
    "    historical_returns = ['Momentum', 'r12_2', 'r12_7', 'r36_13', 'ShortTermReversal', 'LME', 'LTurnover', 'r2_1', 'RET_lag_1_mon']\n",
    "    df[historical_returns] = df.groupby('TICKER')[historical_returns].fillna(method='ffill')\n",
    "    df[historical_returns] = df.groupby('TICKER')[historical_returns].fillna(method='bfill')\n",
    "    df[historical_returns] = df[historical_returns].fillna(df[historical_returns].median())\n",
    "\n",
    "    \n",
    "    # 对交易相关指标使用中位数填充\n",
    "    trading_indicators = ['DollarVolume', 'spread']\n",
    "    df[trading_indicators] = df[trading_indicators].fillna(df[trading_indicators].median())\n",
    "    \n",
    "    # 对SUV使用0填充\n",
    "    df['SUV'] = df['SUV'].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 应用函数\n",
    "df = handle_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())  # 检查前几行数据\n",
    "print(df.isnull().sum())  # 计算NaN的数量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['date']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_and_fill_numeric(df, var):\n",
    "#     # 尝试将数据转换为数值型\n",
    "#     df[var] = pd.to_numeric(df[var], errors='coerce')    \n",
    "#     return df\n",
    "    \n",
    "# # 对每个需要处理的变量应用此函数\n",
    "# variables_to_clean = ['Momentum', 'r12_2', 'r12_7', 'r36_13', 'sprtrn', 'RET', 'RET_lag_1_mon']  # 添加所有需要处理的变量\n",
    "# for var in variables_to_clean:\n",
    "#     df = clean_and_fill_numeric(df, var)\n",
    "    \n",
    "def handle_remaining_missing_values(df):\n",
    "    # 处理 Momentum 和长期回报指标\n",
    "    long_term_vars = ['Momentum', 'r12_2', 'r12_7', 'r36_13']\n",
    "    for var in long_term_vars:\n",
    "        df[var] = df.groupby('SICCD')[var].transform(lambda x: x.fillna(x.median()))\n",
    "        df[var] = df[var].fillna(df[var].median())\n",
    "\n",
    "    # 获取仍然缺失 Momentum 的公司\n",
    "    missing_momentum_companies = df[df['Momentum'].isna()]['TICKER'].unique()\n",
    "    # 使用行业平均值填充\n",
    "    df['Momentum'] = df.groupby('SICCD')['Momentum'].transform(lambda x: x.fillna(x.mean()))\n",
    "    # 用总体平均值填充\n",
    "    df['Momentum'] = df['Momentum'].fillna(df['Momentum'].median())\n",
    "\n",
    "    # 处理短期指标\n",
    "    short_term_vars = ['ShortTermReversal', 'LME', 'LTurnover', 'r2_1']\n",
    "    df[short_term_vars] = df.groupby('TICKER')[short_term_vars].fillna(method='ffill')\n",
    "    df[short_term_vars] = df.groupby('TICKER')[short_term_vars].fillna(method='bfill')\n",
    "    df[short_term_vars] = df[short_term_vars].fillna(df[short_term_vars].median())\n",
    "\n",
    "    for var in short_term_vars:\n",
    "        df[var] = df.groupby('SICCD')[var].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    # 重新计算 Beta 和相关指标\n",
    "    def calculate_beta(stock_returns, market_returns, window=52):\n",
    "        return stock_returns.rolling(window=window).apply(lambda x: np.cov(x, market_returns[-window:])[0,1] / np.var(market_returns[-window:]))\n",
    "\n",
    "    df['Beta'] = df.groupby('TICKER')['RET'].apply(lambda x: calculate_beta(x, df['sprtrn']))\n",
    "    df['BetaSquared'] = df['Beta'] ** 2\n",
    "    \n",
    "    # 对Beta相关指标使用行业平均值填充\n",
    "    beta_indicators = ['Beta', 'BetaSquared','idio_vol']\n",
    "    for indicator in beta_indicators:\n",
    "        df[indicator] = df.groupby('SICCD')[indicator].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    # 如果仍有缺失值（例如，某些公司可能全部为NaN），使用整体中位数填充\n",
    "    for indicator in beta_indicators:\n",
    "        df[indicator] = df[indicator].fillna(df[indicator].median())\n",
    "    \n",
    "    # 用行业中位数\n",
    "    # df[indicator] = df.groupby('SICCD')[indicator].transform(lambda x: x.fillna(x.mean()))\n",
    "    # # 如果仍有缺失值，使用整体中位数填充\n",
    "    # df[indicator] = df[indicator].fillna(df[indicator].median())\n",
    "\n",
    "    df_temp = pd.DataFrame()    \n",
    "    \n",
    "    # 对52周高点相关指标使用3个月高点替代\n",
    "    df_temp['3_month_high'] = df.groupby('TICKER')['PRC'].rolling(window=63).max().reset_index(0, drop=True)\n",
    "    df_temp['Rel_to_3month_high'] = df['PRC'] / df_temp['3_month_high']\n",
    "    \n",
    "    # 使用 1 个月高点\n",
    "    df_temp['1_month_high'] = df.groupby('TICKER')['PRC'].rolling(window=21).max().reset_index(0, drop=True)\n",
    "    df_temp['Rel_to_1month_high'] = df['PRC'] / df_temp['1_month_high']\n",
    "    \n",
    "    # 处理可能的缺失值\n",
    "    df['52_week_high'] = df.groupby('TICKER')['52_week_high'].fillna(method='ffill',limit = 3)\n",
    "    df['Rel_to_high'] = df.groupby('TICKER')['Rel_to_high'].fillna(method='ffill',limit = 3)\n",
    "\n",
    "    # 如果还有缺失值，使用3个月高点填充52周高点\n",
    "    df['52_week_high'] = df['52_week_high'].fillna(df_temp['3_month_high'])\n",
    "    df['Rel_to_high'] = df['Rel_to_high'].fillna(df_temp['Rel_to_3month_high'])\n",
    "\n",
    "    # 如果还有缺失值，使用1个月高点填充52周高点\n",
    "    df['52_week_high'] = df['52_week_high'].fillna(df_temp['1_month_high'])\n",
    "    df['Rel_to_high'] = df['Rel_to_high'].fillna(df_temp['Rel_to_1month_high'])\n",
    "\n",
    "    # 如果还有缺失值，使用当前价格填充52周高点，Rel_to_high填充为1\n",
    "    df['52_week_high'] = df['52_week_high'].fillna(df['PRC'])\n",
    "    df['Rel_to_high'] = df['Rel_to_high'].fillna(1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 应用函数\n",
    "df = handle_remaining_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.columns).to_csv('dfcolumns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.reset_index(inplace = True)\n",
    "\n",
    "# df.set_index(['date','TICKER'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# def calculate_rolling_beta_and_idio_vol(df, window=60):\n",
    "#     # 确保 df 是按日期和股票代码排序的\n",
    "#     df = df.sort_values(['date', 'TICKER'])\n",
    "    \n",
    "#     # 计算市场收益率\n",
    "#     df['market_returns'] = df.groupby('date')['sprtrn'].transform('mean')\n",
    "    \n",
    "#     # 计算每支股票的收益率\n",
    "#     df['stock_returns'] = df.groupby('TICKER')['RET'].pct_change()\n",
    "    \n",
    "#     def rolling_regression(group):\n",
    "#         X = sm.add_constant(group['market_returns'])\n",
    "#         y = group['stock_returns']\n",
    "        \n",
    "#         beta = pd.Series(index=group.index, dtype=float)\n",
    "#         idio_vol = pd.Series(index=group.index, dtype=float)\n",
    "        \n",
    "#         for i in range(window, len(group) + 1):\n",
    "#             model = sm.OLS(y[i-window:i], X[i-window:i]).fit()\n",
    "#             beta.iloc[i-1] = model.params['market_returns']\n",
    "#             idio_vol.iloc[i-1] = np.std(model.resid)\n",
    "        \n",
    "#         return pd.DataFrame({'Beta': beta, 'Idio_vol': idio_vol})\n",
    "    \n",
    "#     result = df.groupby('TICKER').apply(rolling_regression)\n",
    "#     result = result.reset_index()\n",
    "#     result = result.rename(columns={'level_1': 'date'})\n",
    "    \n",
    "#     # 合并结果回原始数据框\n",
    "#     df = pd.merge(df, result, on=['date', 'TICKER'], how='left')\n",
    "    \n",
    "#     # 填充缺失值\n",
    "#     for indicator in ['Beta', 'Idio_vol']:\n",
    "#         df[indicator] = df.groupby('TICKER')[indicator].transform(lambda x: x.fillna(x.median()))\n",
    "#         df[indicator] = df[indicator].fillna(df[indicator].median())\n",
    "    \n",
    "#     # 处理极端值 (可选)\n",
    "#     for indicator in ['Beta', 'Idio_vol']:\n",
    "#         low = df[indicator].quantile(0.01)\n",
    "#         high = df[indicator].quantile(0.99)\n",
    "#         df[indicator] = df[indicator].clip(low, high)\n",
    "    \n",
    "#     # 计算 BetaSquared\n",
    "#     df['BetaSquared'] = df['Beta'] ** 2\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # 使用函数\n",
    "# df = calculate_rolling_beta_and_idio_vol(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values_small_missing(df):\n",
    "    # 处理分类变量\n",
    "    category_vars = ['COMNAM', 'SHRCD', 'EXCHCD', 'SICCD', 'TICKER_encoded', 'SHRCD_encoded', 'EXCHCD_encoded', 'SICCD_encoded']\n",
    "    df[category_vars] = df.groupby('TICKER')[category_vars].fillna(method='ffill')\n",
    "\n",
    "    # 处理数值变量\n",
    "    numeric_vars = ['PRC', 'VOL', 'SHROUT', 'BIDLO', 'ASKHI', 'OPENPRC', 'vwretd', 'ewretd', 'sprtrn', 'RET_calc', 'RET_interp']\n",
    "    df[numeric_vars] = df.groupby('TICKER')[numeric_vars].transform(lambda x: x.interpolate(method='linear'))\n",
    "\n",
    "    # 特殊处理 RET\n",
    "    df['RET'] = df.groupby('TICKER')['RET'].fillna(0)  \n",
    "\n",
    "    small_missing = ['ShortTermReversal', 'LME', 'r2_1', '52_week_high', 'LTurnover', 'Volatility']\n",
    "    df[small_missing] = df.groupby('TICKER')[small_missing].fillna(method='ffill')\n",
    "\n",
    "\n",
    "    # 重新计算 market_cap, ME, 和 Size\n",
    "    df['market_cap'] = df['PRC'].abs() * df['SHROUT']\n",
    "    df['ME'] = df['market_cap']\n",
    "    df['Size'] = np.log(df['ME'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# 应用函数\n",
    "df = handle_missing_values_small_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算缺失值统计，转换为 DataFrame\n",
    "null_summary = pd.DataFrame(df.isnull().sum(), columns=['MissingValueCount'])\n",
    "\n",
    "# 使用 option_context 临时改变显示设置并直接显示 DataFrame\n",
    "with pd.option_context('display.max_columns', None,  'display.max_colwidth', 20):\n",
    "    display(null_summary)\n",
    "\n",
    "null_summary.to_csv(\"missing_value_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True)\n",
    "df.set_index('date',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"final_data_after_missing_value_handle_with_better_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropIndex(dataset):\n",
    "    try:\n",
    "        dataset = dataset.drop(columns = ['level_0', 'index'])\n",
    "    except Exception as e:\n",
    "                print(f\"Issue : {e}\")\n",
    "    return dataset\n",
    "df = dropIndex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     data = data.drop(['level_0_stk','index_stk','3_month_high', 'Rel_to_3month_high', '1_month_high', 'Rel_to_1month_high', 'RET_calc', 'RET_interp'], axis=1)\n",
    "# except KeyError as e:\n",
    "#     print(f\"Columns not found: {e}\")\n",
    "# df.to_csv(\"merged_data_with_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"merged_data_with_features_lag_1_month.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns = pd.DataFrame(df.columns)\n",
    "# df_columns.to_csv('final_data_columns.csv')\n",
    "# print('output df columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_eng_df = pd.DataFrame()\n",
    "# feature_eng_df['TICKER'] = df['TICKER']\n",
    "# feature_eng_df['date'] = df['date']\n",
    "# feature_eng_df[existing_vars] = df[existing_vars]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对于月度特征，使用当前月的数据\n",
    "# # 对于季度特征，使用4个月前的数据\n",
    "# sto_data_selected['QuarterlyFeature_Lagged'] = sto_data_selected.groupby('PERMNO')['QuarterlyFeature'].shift(4)\n",
    "\n",
    "# # 对于年度特征，使用6个月前的数据\n",
    "# sto_data_selected['AnnualFeature_Lagged'] = sto_data_selected.groupby('PERMNO')['AnnualFeature'].shift(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Paused) Further Feature Engineering with Kronecker Product (Macro x others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fin_columns, sto_columns, macro_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for macro_var in macro_data_scaled.columns:\n",
    "#     for fin_var in fin_data.columns:\n",
    "#         fin_data[f'{fin_var}_{macro_var}'] = fin_data[fin_var] * macro_data_scaled[macro_var]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Lags and Hyper-parameter Opitimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 创建滞后特征\n",
    "# def create_lag_features(df, lags, target):\n",
    "#     for lag in lags:\n",
    "#         df[f'{target}_lag{lag}'] = df[target].shift(lag)\n",
    "#     return df\n",
    "\n",
    "# # 假设我们选择滞后1到3\n",
    "# lags = [1, 2, 3, 4]\n",
    "# model_data = create_lag_features(model_data, lags, 'RET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization(FR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_data_after_missing_value_handle_with_better_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropIndex(dataset):\n",
    "    try:\n",
    "        dataset = dataset.drop(columns = ['index'])\n",
    "    except Exception as e:\n",
    "                print(f\"Issue : {e}\")\n",
    "    return dataset\n",
    "data = dropIndex(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果日期已经是索引，先重置索引\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# 设置多级索引\n",
    "data.set_index(['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     data = data.drop(['level_0_stk','index_stk','3_month_high', 'Rel_to_3month_high', '1_month_high', 'Rel_to_1month_high', 'RET_calc', 'RET_interp'], axis=1)\n",
    "# except KeyError as e:\n",
    "#     print(f\"Columns not found: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data.dtypes).to_csv('check_data_info().csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description = data.describe()\n",
    "# description.to_csv('data_description.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle fin related data\n",
    "# 处理无穷大和NaN值\n",
    "data = data.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 创建一个新的DataFrame来存储归一化后的数据\n",
    "normalized_data = pd.DataFrame(index=data.index)\n",
    "\n",
    "\n",
    "# 1. MinMaxScaler用于大多数财务比率\n",
    "minmax_cols = ['CAPEI', 'bm', 'evm', 'pe_op_basic', 'pe_op_dil', 'pe_exi', 'pe_inc', 'dpr', 'npm', \n",
    "               'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm', 'roa', 'roe', 'roce', 'efftax']\n",
    "minmax_scaler = MinMaxScaler()\n",
    "for date in normalized_data.index.unique():\n",
    "    normalized_data[minmax_cols] = minmax_scaler.fit_transform(data[minmax_cols].fillna(data[minmax_cols].mean()))\n",
    "\n",
    "# 2. 对数转换后StandardScaler用于严重偏斜的正值数据\n",
    "log_standard_cols = ['ps', 'pcf', 'debt_ebitda', 'lt_ppent', 'dltt_be', 'debt_assets', 'debt_capital', 'de_ratio']\n",
    "log_standard_scaler = StandardScaler()\n",
    "for col in log_standard_cols:\n",
    "    for date in normalized_data.index.unique():\n",
    "        # 将负值设为很小的正数\n",
    "        temp_data = data[col].clip(lower=1e-8)\n",
    "        normalized_data[col] = log_standard_scaler.fit_transform(np.log1p(temp_data).values.reshape(-1, 1))\n",
    "\n",
    "# 3. Yeo-Johnson变换用于可能包含负值的财务指标\n",
    "yeojohnson_cols = ['aftret_eq', 'aftret_invcapx', 'aftret_equity', 'pretret_noa', 'pretret_earnat', 'GProf']\n",
    "pt_yeo = PowerTransformer(method='yeo-johnson')\n",
    "for date in normalized_data.index.unique():\n",
    "    normalized_data[yeojohnson_cols] = pt_yeo.fit_transform(data[yeojohnson_cols].fillna(data[yeojohnson_cols].mean()))\n",
    "\n",
    "# 4. 对于0-1之间的比率数据，使用缩放而不是logit转换\n",
    "ratio_cols = ['equity_invcap', 'debt_invcap', 'totdebt_invcap', 'capital_ratio']\n",
    "ratio_scaler = MinMaxScaler(feature_range=(0.001, 0.999))  # 避免0和1\n",
    "for date in normalized_data.index.unique():\n",
    "    normalized_data[ratio_cols] = ratio_scaler.fit_transform(data[ratio_cols].fillna(data[ratio_cols].mean()))\n",
    "\n",
    "# 5. 对于周转率和转换天数，使用Yeo-Johnson而不是Box-Cox\n",
    "turn_cols = ['inv_turn', 'at_turn', 'rect_turn', 'pay_turn', 'cash_conversion']\n",
    "pt_yeo_turn = PowerTransformer(method='yeo-johnson')\n",
    "for date in normalized_data.index.unique():\n",
    "    normalized_data[turn_cols] = pt_yeo_turn.fit_transform(data[turn_cols].fillna(data[turn_cols].mean()))\n",
    "\n",
    "# 6. QuantileTransformer用于可能存在极端值的指标\n",
    "quantile_cols = ['intcov', 'intcov_ratio', 'cash_ratio', 'quick_ratio', 'curr_ratio', 'sale_invcap', 'sale_equity', 'sale_nwc']\n",
    "qt = QuantileTransformer(output_distribution='normal')\n",
    "for date in normalized_data.index.unique():\n",
    "    normalized_data[quantile_cols] = qt.fit_transform(data[quantile_cols].fillna(data[quantile_cols].mean()))\n",
    "\n",
    "# 7. RobustScaler用于其他可能包含异常值的列\n",
    "robust_cols = ['int_debt', 'int_totdebt', 'cash_lt', 'invt_act', 'rect_act', 'debt_at', 'short_debt', 'curr_debt', 'lt_debt', \n",
    "               'profit_lct', 'ocf_lct', 'cash_debt', 'fcf_ocf', 'rd_sale', 'adv_sale', 'staff_sale', 'accrual', 'ptb', 'PEG_trailing', 'divyield',\n",
    "              'r2_1', 'r12_2', 'r12_7', 'Volatility', 'SUV', '52_week_high', 'Rel_to_high']\n",
    "robust_scaler = RobustScaler()\n",
    "for date in normalized_data.index.unique():\n",
    "    normalized_data[robust_cols] = robust_scaler.fit_transform(data[robust_cols].fillna(data[robust_cols].mean()))\n",
    "\n",
    "# 检查是否所有列都已处理\n",
    "unprocessed_cols = set(numeric_columns) - set(normalized_data.columns)\n",
    "if unprocessed_cols:\n",
    "    print(f\"Warning: The following columns were not processed: {unprocessed_cols}\")\n",
    "    # 对于未处理的列，可以选择直接复制原始值或应用默认的StandardScaler\n",
    "    for col in unprocessed_cols:\n",
    "        for date in normalized_data.index.unique():\n",
    "            normalized_data[col] = StandardScaler().fit_transform(data[[col]].fillna(data[col].mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle stock and econ related data\n",
    "\n",
    "# 创建归一化器\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# 选择需要进行 Min-Max 归一化的特征\n",
    "min_max_features = [\n",
    "    'vwretd', 'ewretd', 'sprtrn',\n",
    "    'Beta', 'BetaSquared', 'idio_vol', 'spread', 'BM', 'ME', 'Size',\n",
    "    'Momentum', 'ShortTermReversal', 'LME', 'LTurnover'\n",
    "]\n",
    "\n",
    "# 选择需要进行 Z-score 标准化的特征\n",
    "z_score_features = [\n",
    "    'PRC', 'VOL', 'SHROUT', 'BIDLO', 'ASKHI', 'OPENPRC',\n",
    "    'market_cap', 'TB3MS', 'T10Y2Y', 'BAA10Y', 'DollarVolume'\n",
    "]\n",
    "\n",
    "# 进行 Min-Max 归一化\n",
    "for date in normalized_data.index.unique():\n",
    "    normalized_data[min_max_features] = min_max_scaler.fit_transform(data[min_max_features])\n",
    "\n",
    "# 进行 Z-score 标准化\n",
    "for date in normalized_data.index.unique():\n",
    "    normalized_data[z_score_features] = standard_scaler.fit_transform(data[z_score_features])\n",
    "\n",
    "# 显示归一化后的数据\n",
    "print(normalized_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data['TICKER'] = data['TICKER']\n",
    "normalized_data['RET'] = data['RET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_data.to_csv('normalized_data.csv', index=True)\n",
    "\n",
    "print(\"Normalization completed. Data saved to 'normalized_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank standardization in inreval [-1,1]\n",
    "A rank standardization procedure following Kelly, Pruitt, and Su (2019) and Freyberger, Neuhierl, and Weber (2020) is employed. The stock characteristics are ranked month-by-month cross-sectionally and the ranks are mapped into the [-1,1] interval, thereby transforming features into a uniform distribution and increasing the insensitivity to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nor_data = normalized_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = (minmax_cols + log_standard_cols + yeojohnson_cols +\n",
    "                ratio_cols + turn_cols + quantile_cols + robust_cols +\n",
    "                min_max_features + z_score_features)\n",
    "\n",
    "# 对每个月（由 'eom' 列指示的月份）进行分组，然后对这些特征进行百分比排名\n",
    "temp_nor_data[all_features] = temp_nor_data[all_features].rank(pct=True)\n",
    "\n",
    "# 将排名转换为 [-1, 1] 区间\n",
    "temp_nor_data[all_features] = 2 * temp_nor_data[all_features] - 1\n",
    "\n",
    "# 检查转换结果\n",
    "print(temp_nor_data[all_features].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nor_data['TICKER'] = data['TICKER']\n",
    "temp_nor_data['RET'] = data['RET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存归一化后的数据\n",
    "# temp_nor_data.to_csv('temp_nor_data.csv', index=True)\n",
    "\n",
    "print(\"Normalization completed. Data saved to 'normalized_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nor_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_nor_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先用正常的经过二次feature过的data（final_data_after_missing_value_handle_with_better_features）试试\n",
    "# model_data = pd.read_csv('final_data_after_missing_value_handle_with_better_features.csv')\n",
    "\n",
    "#再用归一化的data（temp_nor_data）试一试\n",
    "model_data = pd.read_csv('temp_nor_data.csv')\n",
    "\n",
    "#再用标准化的data（normalized_data）试一试\n",
    "# model_data = pd.read_csv('normalized_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果日期已经是索引，先重置索引\n",
    "model_data.reset_index(drop=False, inplace=True)\n",
    "\n",
    "model_data['date'] = pd.to_datetime(model_data['date'])\n",
    "\n",
    "# 设置多级索引\n",
    "model_data.set_index(['date'], inplace=True)\n",
    "\n",
    "# def dropIndex(dataset):\n",
    "#     try:\n",
    "#         dataset = dataset.drop(columns = ['index'])\n",
    "#     except Exception as e:\n",
    "#         print(f\"Issue : {e}\")\n",
    "#     return dataset\n",
    "# df = dropIndex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集为训练集和最后一个月的预测集\n",
    "last_month = model_data.index.max()\n",
    "model_data_for_training = model_data[model_data.index < last_month]\n",
    "model_data_using_model_predicting = model_data[model_data.index == last_month]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可能需要删除的变量\n",
    "variables_to_drop = [\n",
    "    'CAPEI', 'evm', 'pe_exi', 'pe_inc', 'ptpm', 'pcf',\n",
    "    'aftret_eq', 'aftret_invcapx', 'aftret_equity',\n",
    "    'pretret_noa', 'pretret_earnat',\n",
    "    'equity_invcap', 'debt_invcap', 'totdebt_invcap',\n",
    "    'intcov', 'intcov_ratio',\n",
    "    'sale_invcap', 'sale_equity', 'sale_nwc',\n",
    "    'int_debt', 'int_totdebt',\n",
    "    'invt_act', 'rect_act',\n",
    "    'short_debt', 'curr_debt', 'lt_debt',\n",
    "    'ptb', 'PEG_trailing'\n",
    "]\n",
    "\n",
    "# existing_vars = [\n",
    "    # 'market_cap',  # ME (Market Equity)\n",
    "    # 'bm',          # Book-to-Market\n",
    "    # 'pe_op_basic', # E2P (inverse)\n",
    "    # 'pe_op_dil',   # Another version of E2P (inverse)\n",
    "    # 'npm',         # Similar to PM (Profit Margin)\n",
    "    # 'gpm',         # Similar to PCM (Price-to-Cost Margin)\n",
    "    # 'roa',         # Return on Assets\n",
    "    # 'roe',         # Return on Equity\n",
    "    # 'ps',          # Price to Sales (inverse of S2P)\n",
    "    # 'debt_assets', # Similar to Lev (Leverage)\n",
    "    # 'at_turn',     # Similar to ATO (Asset Turnover)\n",
    "    # 'accrual',     # Might correspond to OA (Operating Accruals)\n",
    "    # 'divyield',    # Dividend Yield\n",
    "# ]\n",
    "\n",
    "# 需要保留的变量\n",
    "variables_to_keep = [\n",
    "    # 基准特征\n",
    "    'Size', 'bm', 'Momentum',\n",
    "\n",
    "    # Time-lag\n",
    "    'r2_1', 'r12_2', 'r12_7', \n",
    "    # 'r36_13',  \n",
    "    \n",
    "    # 股票水平预测器\n",
    "    'ShortTermReversal', 'market_cap', 'DollarVolume', 'spread',\n",
    "    'RET', 'idio_vol', 'Beta', 'BetaSquared', \n",
    "    # 'ME',\n",
    "\n",
    "    'pe_op_basic', 'pe_op_dil',\n",
    "    \n",
    "    # 波动性\n",
    "    'Volatility', 'SUV',\n",
    "\n",
    "    # 技术指标\n",
    "    '52_week_high', 'Rel_to_high',\n",
    "    \n",
    "    # 宏观经济预测器 \n",
    "    'TB3MS', 'T10Y2Y', 'BAA10Y', \n",
    "    \n",
    "    # 其他重要财务指标\n",
    "    'roa', 'roe', 'roce', 'debt_assets', 'debt_capital', 'de_ratio',\n",
    "    'cash_ratio', 'quick_ratio', 'curr_ratio', 'at_turn', 'inv_turn',\n",
    "    'accrual',\n",
    "    \n",
    "    # 价格和交易相关\n",
    "    # 'PRC', 'VOL', \n",
    "    # 'SHROUT', 'BIDLO', 'ASKHI', 'OPENPRC',\n",
    "    \n",
    "    # 市场回报指标\n",
    "    'vwretd', 'ewretd', 'sprtrn',\n",
    "    \n",
    "    # 其他可能有用的指标\n",
    "    # 'dpr', 'npm', 'opmbd', 'opmad', 'gpm', 'cfm', 'efftax', 'ps',\n",
    "    # 'debt_ebitda', 'lt_ppent', 'dltt_be', 'capital_ratio',\n",
    "    # 'rect_turn', 'pay_turn', 'cash_conversion',\n",
    "    # 'cash_lt', 'debt_at', 'profit_lct', 'ocf_lct',\n",
    "    # 'cash_debt', 'fcf_ocf', 'rd_sale', 'adv_sale', 'staff_sale',\n",
    "    # 'evm',\n",
    "    # 'divyield',\n",
    "\n",
    "    # 'aftret_eq', 'intcov', 'short_debt', \n",
    "    \n",
    "    # 其他计算得到的指标\n",
    "    'LME', 'LTurnover', \n",
    "     \n",
    "    \n",
    "    # 标识符\n",
    "    'TICKER'\n",
    "]\n",
    "\n",
    "# 使用这些列表来选择或删除变量\n",
    "model_data = model_data[variables_to_keep]\n",
    "# 全部保留\n",
    "\n",
    "# # 或者\n",
    "# df_dropped = df.drop(columns=variables_to_drop)\n",
    "\n",
    "# 打印列表长度，以检查\n",
    "# print(f\"Number of variables to drop: {len(variables_to_drop)}\")\n",
    "# print(f\"Number of variables to keep: {len(variables_to_keep)}\")\n",
    "\n",
    "# try:\n",
    "#     rf_data = rf_data.drop([''], axis=1)\n",
    "# except KeyError as e:\n",
    "#     print(f\"Columns not found: {e}\")\n",
    "\n",
    "#因为结果不好所以不选择变量了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(model_data.columns).to_csv('model_data_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_data.dtypes).to_csv('model_data_dtypess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_have_nan = ['ShortTermReversal','LME','LTurnover']\n",
    "# try:\n",
    "#     model_data[columns_have_nan] = model_data[columns_have_nan].fillna(model_data[columns_have_nan].mean())\n",
    "# except KeyError as e:\n",
    "#     print(f\"Columns not found: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lag过了！！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义不需要滞后的变量\n",
    "non_lag_variables = ['TICKER', 'RET']\n",
    "variables_to_keep = model_data.columns\n",
    "non_annual_features = [\n",
    "    'Size', 'Momentum', 'r2_1', 'r12_2', 'r12_7',\n",
    "    'ShortTermReversal', 'DollarVolume', 'spread', 'idio_vol',\n",
    "    'Beta', 'BetaSquared', 'Volatility', 'SUV',\n",
    "    '52_week_high', 'Rel_to_high', 'TB3MS', 'T10Y2Y', 'BAA10Y',\n",
    "    'vwretd', 'ewretd', 'sprtrn', 'LME', 'LTurnover'\n",
    "]\n",
    "\n",
    "# 定义需要滞后的变量\n",
    "lag_variables = [var for var in variables_to_keep if var not in non_lag_variables]\n",
    "\n",
    "# 假设model_data是一个包含所有数据的DataFrame，并且已经按日期和TICKER排序\n",
    "# 对需要滞后的变量进行滞后处理\n",
    "for var in lag_variables:\n",
    "    if var in non_annual_features:\n",
    "        # 对non_annual_features进行1个月的滞后\n",
    "        model_data[f'{var}_lag'] = model_data.groupby('TICKER')[var].shift(1)\n",
    "    else:\n",
    "        # 其他变量保持6个月的滞后\n",
    "        model_data[f'{var}_lag'] = model_data.groupby('TICKER')[var].shift(6)\n",
    "\n",
    "# 删除原始的非滞后变量（除了不需要滞后的变量）\n",
    "model_data = model_data.drop(columns=lag_variables)\n",
    "\n",
    "# 重命名滞后变量，去掉\"_lag\"后缀\n",
    "model_data = model_data.rename(columns={f'{var}_lag': var for var in lag_variables})\n",
    "\n",
    "# 删除包含NaN值的行（由于滞后处理产生的第一个时间点）\n",
    "model_data = model_data.dropna()\n",
    "\n",
    "# 最终的model_data将包含所有滞后处理后的变量和不需要滞后的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data['RET'] = df.loc[df.index.get_level_values('date') == model_data.index, 'RET'].iloc[0]\n",
    "model_data['RET'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data = model_data.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果日期已经是索引，先重置索引\n",
    "model_data.reset_index(inplace=True)\n",
    "\n",
    "# 设置多级索引\n",
    "# model_data.set_index(['date', 'TICKER'], inplace=True)\n",
    "model_data.set_index(['date'], inplace=True)\n",
    "\n",
    "\n",
    "# 对MultiIndex进行排序\n",
    "model_data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data.to_csv('model_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
